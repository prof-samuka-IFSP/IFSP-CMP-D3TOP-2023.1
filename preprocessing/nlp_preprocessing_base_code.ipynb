{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b27a0ea-69c6-424d-88ad-0782fe5366b9",
   "metadata": {},
   "source": [
    "# NLP Text Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43af6e-102a-496e-9a17-43ae78225aaf",
   "metadata": {},
   "source": [
    "We are going to see several steps/methods used **to clean and preprocess *text data***. <br/>\n",
    "**NOT all** of these steps are _always necessary_, and ***not all*** of them are performed in the order in which we will present here.\n",
    "\n",
    "Inicially, we are going to see some popular **NLP packages** and its differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322326fe-ac96-4dd6-b3d9-f4c5202b9232",
   "metadata": {},
   "source": [
    "## 1. NLP Packages\n",
    "- NLTK: https://www.nltk.org/\n",
    "- spaCy: https://spacy.io/\n",
    "- BeautifulSoup4: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11a748-6a35-4661-9c8a-76087e51c972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74758d-1bca-49c2-9188-aeff642e67de",
   "metadata": {},
   "source": [
    "### Natural Language Toolkit (NLTK)\n",
    "- Popular NLP open source package\n",
    "- Released in 2011\n",
    "- Provides many functinalities to treat and process _text data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c9943-eb80-42af-aa98-2b546ccc0fe8",
   "metadata": {},
   "source": [
    "### SpaCy\n",
    "- Open Source Natural Language Processing Library\n",
    "- Designed to _efficiently_ execute popular algorithms and tackle NLP tasks with maximum _effectiveness_.\n",
    "- SpaCy typically offers _only one_ implemented approach for various NLP tasks, selecting **the most efficient algorithm** that is currently available.\n",
    "- Thus, we cannot choose other algorithms for a given NLP task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab2707-979e-47e3-9dc8-b47d06ee1c52",
   "metadata": {},
   "source": [
    "### NLTK vs SpaCy\n",
    "- In general, SpaCy is considerably **faster and more efficient** than NLTK.\n",
    "- In turn, NLTK provides **pre-trained models** for some applications, such as _sentiment analysis_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e39b0-31ab-46a6-a419-ac9d06e69e20",
   "metadata": {},
   "source": [
    "### 1.1 Dive into SpaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7302cc-8334-44b8-aa9a-da02f50ef9b0",
   "metadata": {},
   "source": [
    "#### Loading SpaCy for a given Language\n",
    " - **English:** https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263a2198-5a64-4a80-9cbb-326a6e5b19d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c60f80b-73de-46b7-a72f-225bdeb6ea57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab86227-13c1-4d5e-a927-c16d4bfb24c1",
   "metadata": {},
   "source": [
    "- **Portuguese:** https://spacy.io/models/pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22831c-b021-4d15-b730-c1f5c402e403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc4c26-269b-4cf5-afe4-6121860853c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a66f185-3645-4bfb-b1df-d57ba617fc51",
   "metadata": {},
   "source": [
    "#### SpaCy (Preprocessing) Pipeline\n",
    "SpaCy works with a _Pipeline object_.\n",
    "\n",
    "<img src='./imgs/spacy_pipeline.png' width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe01f1-5edd-4c14-b0d4-b5f4896fd3f9",
   "metadata": {},
   "source": [
    "From [official documentation](https://spacy.io/usage/spacy-101#pipelines):\n",
    "- When you call `nlp` on a _text_, spaCy first **tokenizes** the _text_ to produce a `Doc object`.\n",
    "- The `Doc` is then processed in several different steps ‚Äì this is also referred to as the **processing pipeline**.\n",
    "- The pipeline used by the _trained pipelines_ typically include a `tagger`, a `lemmatizer`, a `parser` and an `entity recognizer`.\n",
    "- Each pipeline component returns the **processed `Doc`**, which is then passed on to the next component.\n",
    "\n",
    "<img src='./imgs/spacy_pipeline_table.png' width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb1a21-79ce-4b8b-8467-981213d20329",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6878028c-9bd8-4643-9f6e-0d42446654e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The sun is a massive, luminous ball of gas that is the center of our solar system. It is estimated to be around 4.6 billion years old and has a diameter of about 1.39 million kilometers. The sun's energy is produced through a process called nuclear fusion, where hydrogen atoms combine to form helium and release a tremendous amount of energy in the process.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfdd27-ca1a-490c-a46f-6416f2fb1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4a209-d357-4a3e-8168-4cba929b9937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6308a-9ff7-4ce7-b92d-5a44a72e0dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b8467-eac5-4a89-8c91-8b94ab34208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487321e-2e1e-4347-8f98-6a241e709258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language of the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140ed73-e4d7-4828-be16-c610ea299121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each token/word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c7a6e-4614-4ee9-ab03-5f0bea2e9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each token/word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774bfba7-cd40-4073-822a-286b877bd677",
   "metadata": {},
   "source": [
    "## üßπ 2. Text Cleaning\n",
    "- actions of removing something\n",
    "- we can perform some preprocessing before it (e.g., lowering text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a74e4-5d71-4ca5-8697-a80263e1f348",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Remove newlines `\\n` and Tabs `\\t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771b76b-3352-4c9e-87b1-c829fd07d944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_newlines_tabs = \\\n",
    "\"\"\"Cats are fascinating creatures that have captured the hearts of humans for centuries. They are known for their agility, grace, and independence, and their ability to make us laugh and feel comforted. \\n\n",
    "\n",
    "\\tDespite their reputation for being aloof, cats are actually quite social animals and thrive on attention and affection from their owners. They are also highly intelligent and can be trained to do a variety of tricks and behaviors, including using a litter box and walking on a leash. \\n\n",
    "\n",
    "\\tOne of the most endearing things about cats is their tendency to curl up in cozy spots, whether it's a sunny windowsill, a soft bed, or a warm lap. They are also famous for their love of napping, and can often be found snoozing for hours on end. \\n\n",
    "\n",
    "\\tWhile cats may sometimes get a bad rap for being aloof or indifferent, those who have experienced the joy of sharing their lives with a feline friend know that there's nothing quite like the bond between a cat and its human.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224aed2-4ab4-412e-ac43-ad914f1712c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cat_text_newlines_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048754aa-bd05-4c85-9c56-0386b75bbe5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_newlines_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc4530-2908-4585-b5d4-91c115891f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "68960355-64d5-49d5-9d9e-3b4937ecbce2",
   "metadata": {
    "tags": []
   },
   "source": [
    "remove_newlines_tabs(cat_text_newlines_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8f1a9-42fe-4085-b2a2-9a9e7bbef2df",
   "metadata": {},
   "source": [
    "### 2.2. Strip HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabac21-7a1b-4a64-8da5-273479f12ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_html_text = '''<p><i><b>Harry Potter and the Philosopher's Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy novel\">fantasy novel</a> written by British author <a href=\"/wiki/J._K._Rowling\" title=\"J. K. Rowling\">J. K. Rowling</a>. The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry Potter\">Harry Potter</a></i> series and Rowling's <a href=\"/wiki/Debut_novel\" title=\"Debut novel\">debut novel</a>, it follows <a href=\"/wiki/Harry_Potter_(character)\" title=\"Harry Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a>. Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione Granger\">Hermione Granger</a>, he faces an attempted comeback by the dark wizard <a href=\"/wiki/Lord_Voldemort\" title=\"Lord Voldemort\">Lord Voldemort</a>, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\n",
    "</p>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e873d-f486-40ba-a4e7-739f5043036c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hp_html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b412123-a398-417e-bf97-ff4c6c8c23bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5755574c-cd5b-415d-bce2-d14238008a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strip_html_tags(hp_html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed06a7-ae0f-43d4-82c9-8480bb8a0328",
   "metadata": {},
   "source": [
    "### 2.3. Remove Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea98bdb-13c9-46a4-881c-3ce89115bf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_with_links = \\\n",
    "'''Cats are amazing animals that have been domesticated for thousands of years. They are beloved by many people for their adorable appearance, unique personalities, and entertaining antics. Cats are also known for their ability to form strong bonds with their human companions.\n",
    "If you're a cat lover looking for more information about these fascinating creatures, there are many resources available online. You can visit websites like http://www.catster.com/ to learn more about cat breeds, behavior, and health. For more in-depth information, check out https://www.vet.cornell.edu/departments-centers-and-institutes/cornell-feline-health-center, which offers comprehensive resources for cat owners and veterinarians.\n",
    "If you're interested in adopting a cat or finding a local shelter, petfinder.com/cats/ is a great resource. This website allows you to search for cats available for adoption in your area and provides helpful information about the adoption process.\n",
    "Whether you're a seasoned cat owner or simply a cat enthusiast, these websites can provide you with valuable information and resources to help you better understand and care for your feline friends.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d9b2a5-5efb-47cd-a6e5-93508dd2855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(cat_text_with_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377f8a8-788c-4d3f-9583-59e1377d80c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_with_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f52873-bd45-4014-9ed6-d4081b5fe399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4dedb-b10e-46b5-8545-19c3bf25b8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_links(cat_text_with_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b9cbc2-3c35-4c9b-aec1-78cb6027269f",
   "metadata": {},
   "source": [
    "### 2.4. Remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbafa5-4918-4b5d-b199-67fe56a97c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "venice_text = \\\n",
    "'''Venice           is a city unlike any other, built on a network of     canals and filled with historic architecture and     cultural treasures.    Its unique layout and beautiful surroundings      have made it a      top tourist destination, attracting millions of visitors    each year.        The city is home to many iconic     landmarks, such as the Rialto Bridge, St. Mark's Basilica,     and the Doge's     Palace, which offer a glimpse into Venice's     rich history and artistic legacy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228141c-691b-4226-a9bf-5aa319ca193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "venice_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e8063-3d3a-4af9-898f-4e5f677daa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cdf3cb-9507-4e62-bc20-580808f06bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_extra_whitespaces(venice_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef89301-c327-48fe-a223-70d143becd0a",
   "metadata": {},
   "source": [
    "### 2.5. Unicode Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98280ab3-dc77-49c9-afcd-b5a3036a4f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salvador_text = \"Salvador is a city full of life, culture, and history üåáüé≠üè∞. From the beautiful beaches üåäüèñÔ∏è to the vibrant music and dance scene üíÉüï∫üé∂, there's never a dull moment in this exciting Brazilian city üáßüá∑.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453bc130-5904-4d5d-a77f-c32fc553ea4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salvador_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6cc76d-0916-4b9b-b174-0d3a0e7d504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407fae1-10b3-4ce9-8602-68eba6273053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unicode_normalization(salvador_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccff61-0a25-47a2-8e10-e35db0913616",
   "metadata": {},
   "source": [
    "### 2.6. Removing Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87133142-5d59-4a3a-805b-85bddb5aeb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    regex_emoticons = u\"\\U0001F600-\\U0001F64F\"\n",
    "    regex_symbols_pictographs = u\"\\U0001F300-\\U0001F5FF\"\n",
    "    regex_transport_map_symbols = u\"\\U0001F680-\\U0001F6FF\"\n",
    "    regex_flags_ios = u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "    \n",
    "    regex = f\"\\s+[{regex_emoticons}{regex_symbols_pictographs}{regex_transport_map_symbols}{regex_flags_ios}]+\"\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17b68e-7bc0-4d36-a4ad-d29c7342d651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "remove_emojis(salvador_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20c357-da24-4d83-91fc-499422e7214d",
   "metadata": {},
   "source": [
    "## üõ† 3. Preprocessing\n",
    "\n",
    "<img src='./imgs/preprocessing_pipeline.png' width=600 />\n",
    "\n",
    "**Source:** Vajjala et al. (2020), 'Practical Natural Language Processing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc9585-8e59-45c0-a688-55e294a86504",
   "metadata": {},
   "source": [
    "### 3.1. Lowercasing\n",
    "To prevent the _same word_ written with _different CASES_ from being interpreted _differently_ in future steps of NLP, we perform **lowering** to _standardize_ them with _lowercase letters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb3063-3310-43f4-a35e-8aefde312502",
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_cream_text = 'My favorite ice cream flavor is Chocolate. Ow, I love CHOCOLATE ICE CreAM.'\n",
    "ice_cream_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffae05-f4c7-4f9c-ac1f-24bcd866e2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f3f5718-aa77-4b5e-aaef-293f47c2ccc0",
   "metadata": {},
   "source": [
    "### 3.2. Sentence segmentation\n",
    "- We can do **sentence segmentation** by _breaking up_ text into **sentences** at the appearance of _full stops_ and _question marks_.\n",
    "- However, there may be abbreviations, forms of addresses (Dr., Mr., etc.), or ellipses (...) that may break the simple rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa143a61-ce9c-46b5-934b-ad9d8a303fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_text = \\\n",
    "'''Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works. It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
    "\n",
    "One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text. This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
    "\n",
    "However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively. Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing. As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba0ad0-0887-406c-9d53-2cc39a592dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dl_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34227d9-d3d4-4228-84d6-5be30e001db9",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f2d70-2f8d-488e-aabe-0bc1e27c282c",
   "metadata": {},
   "source": [
    "**Punkt Sentence Tokenizer** - `nltk.tokenize.punkt module`\n",
    "- This **tokenizer** divides _a text_ into **a list of *sentences*** by using an _unsupervised algorithm_ to build a model for abbreviation words, collocations, and words that start sentences.\n",
    "- It **must** be _trained on a large collection of plaintext_ in the **target language** before it can be used.\n",
    "- The NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.punkt.html#module-nltk.tokenize.punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7990e-17b2-4509-b43e-e2dce5703c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# downloading the pre-trained tokenizers\n",
    "# download on: /home/your_user/nltk_data/tokenizers/punkt\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff998b2-bee8-45d4-9e97-674048cadcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the (downloaded) available tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa03bbc-a39a-4b4d-96d2-a1bbbf52aca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls ~/nltk_data/tokenizers/punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe42e7-6c55-4ec2-bba3-64a6dfa7d01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b49a01-6c79-465f-bbb6-cf2c1a09fef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example 1 in English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713d330-30c4-44b6-b72a-7f5b1cc37514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(dl_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d621a5-0ead-4883-b7eb-5eeb2b6d5c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(dl_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f5744-a4be-4abc-9491-ad6f1e16797d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example 2 (with HTML) in English\n",
    "hp_html_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4cf3f-ee49-41cf-a254-069c4dcd15aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec3fcf9-769a-4d3a-890d-c79db3d17c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(hp_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fa99dd-1bfc-4e11-a8f0-a801600bf2fb",
   "metadata": {},
   "source": [
    "**Tokenizer doesn't** deal with HTML tags. See the last segmented sentence, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee50a5-e729-4976-87ca-361a72edc780",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffd4b5-b10e-49ee-a4aa-169b8951544a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3f479-e37c-4842-bdc8-6a9dd13c4bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5b96f-87d5-4018-82fa-df9af540f32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6a1e4-d574-4046-97cd-ed73296d0aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(dl_sentences_spacy):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3c394-43e1-415c-8013-f4c536d9b925",
   "metadata": {},
   "source": [
    "`SpaCy` keeps the `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5b22e5-77c6-4589-bb75-ab7cb7aa7f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed233f34-1ed0-4157-bac9-17ba62974338",
   "metadata": {},
   "source": [
    "**`SpaCy` doesn't** deal with HTML tags. See the last segmented sentence, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d34621e-a269-4dc4-9b6b-7c7a6a088686",
   "metadata": {},
   "source": [
    "#### **Portuguese**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756ffc35-57ea-4b80-b487-79906424c735",
   "metadata": {},
   "source": [
    "##### **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52ac48-c013-4530-8bfa-8aceb39d5a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suco_text = \\\n",
    "'''Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante. Rico em vitamina C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\n",
    "\n",
    "Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado. Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\n",
    "\n",
    "Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano. Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb0f15-44b3-4b83-a692-19cf3d859f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(suco_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679c956-5b72-4189-bef5-37975fc79929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7519bfd-e525-4729-be49-76f1e9367a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(suco_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f4ff5f-9f9b-42fa-b818-710478f8d23c",
   "metadata": {},
   "source": [
    "##### **SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e5720-0cca-4843-9dc6-1ce15d208c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a570c6-d0de-42d4-b343-e59aecb0da1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b6cd5-c775-4adc-9a5d-f8eed456f873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(suco_sentences_spacy):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ce7ff-470d-4743-be28-5c47acf14f65",
   "metadata": {},
   "source": [
    "### 3.3. Word tokenization\n",
    "#### NLTK\n",
    "- To **tokenize** a _sentence_ into **words**, we can start with a simple rule to split text into words based on the presence of **punctuation marks**.\n",
    "- The NLTK library allows us to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8735ec-3682-448a-a40e-ba1267d29e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c856c-62b1-4c4e-a3e5-178b84ad35b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee39e87-8f41-4672-84aa-61f810b8621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(dl_sentences):\n",
    "    print(i, sentence)\n",
    "    print(word_tokenize(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59553f7f-406b-4b90-bc5d-a5bd1e09eb43",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We can also perform **word tokenization** in the _entire text_ directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4912c51f-3ae1-4715-9337-ad310be52a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(dl_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e7d41-4afd-4237-8020-337cc53ca0ad",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0ea21-9bab-4e1b-93b6-18f18a68e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b82e7-f40b-45c0-a32a-5fadda9a1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7284556-6c25-4b67-88d8-82dd563e46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(dl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61b33de-b442-4209-a998-238bf7a090e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b066fe11-bd56-4861-93ba-bc8d79d9114d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "126862d4-da16-447b-ba91-a5666b26c1ac",
   "metadata": {},
   "source": [
    "#### Word Tokenizers may be imprecise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ea021-effd-4956-b205-1211b4a8fcb8",
   "metadata": {},
   "source": [
    "**Example 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394349ca-08ca-4a60-a6af-ecf6ef823895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Mr. Jack O‚ÄôNeil works at Melitas Marg, located at 245 Yonge Avenue, Austin, 70272.\"\n",
    "sentence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64216cde-a7f4-48d0-b0fd-6722c16f695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "print(word_tokenize(sentence_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce752847-da13-4c3d-8ee4-afeaaad1d8e3",
   "metadata": {},
   "source": [
    "Note that, using `NLTK`, _O, ‚Äò_, and _Neil_ are identified as three separate tokens, which is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d6331-b589-4895-b58c-3a146df68138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy\n",
    "doc = nlp(sentence_1)\n",
    "\n",
    "tokens = [token for token in doc]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929db945-330f-468a-915c-c1ec2c303898",
   "metadata": {},
   "source": [
    "Now, using `SpaCy`, O'Neil was considered a single token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a2d3e-c65c-4a2c-ab5a-3d3168d7ef37",
   "metadata": {},
   "source": [
    "**Example 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060bad34-be6d-452b-bf01-1ba0f7147b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_2 = \"There are $10,000 and ‚Ç¨1000 which are there just for testing a tokenizer\"\n",
    "sentence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936f069-233a-4bdb-89e5-c7225bb7441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "print(word_tokenize(sentence_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da92669-040c-4423-9ff7-d6b6e4c9ac2a",
   "metadata": {},
   "source": [
    "While `$` and `10,000` are identified as _separate tokens_, `‚Ç¨1000` is identified as a _single token_ in `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a509ea8-1535-42a6-8f9c-91c6bee3fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy\n",
    "doc = nlp(sentence_2)\n",
    "\n",
    "tokens = [token for token in doc]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75d12e-9881-43b0-a945-a1a61efd3e6d",
   "metadata": {},
   "source": [
    "Both money signs were identified as _separated tokens_ in `spaCy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f083b43-1bf7-4c5d-a5e3-7fe0faa0e29e",
   "metadata": {},
   "source": [
    "##### **Casual Word Tokenizers**\n",
    "In some cases, as Tweets or post in other social networks, the _standard word tokenization_ may be _even more imprecise_ due to **casual language** and **custom symbols** (e.g., @, #, ...). <br/>\n",
    "Some NLP packages, such as NLP, also provides a specific _word tokenizer_ for such cases.\n",
    "\n",
    "For example, NLTK `TweetTokenizer`: https://www.nltk.org/api/nltk.tokenize.casual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afa586-0163-4d67-86bb-dd80e01d5c93",
   "metadata": {},
   "source": [
    "##### **Tokenization is language-dependent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e12449-805c-4159-a8b4-004cadc01a5b",
   "metadata": {},
   "source": [
    "**Tokenization** is also **_heavily_ dependent on language**.\n",
    "\n",
    "For example, **'N.Y.!'** has a total of _three punctuations_, but in English, **N.Y.** stands for New York, hence **'N.Y.'** should be treated as a **single word** and not be tokenized further.\n",
    "\n",
    "Such _language-specific exceptions_ can be specified in some NLP packages. NLTK treats this specific situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4919b5-fd54-47d8-9e82-1ee3c4b51bcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.4. Correcting mis-spelled words\n",
    "- Be careful, because this preprocessing task might change the true meaning of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8459df-43e6-4b07-ad03-937c9f7f3377",
   "metadata": {},
   "source": [
    "**Required package - Text Blob**\n",
    "https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "`textblob` **only corrects spelling in English**. There is some alternative packages, such as [`pyspellchecker`](https://pyspellchecker.readthedocs.io/en/latest/), that supports Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c8958-c78a-45e0-bff9-af65cd841e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28720a-c4a8-4cca-aa42-e1614ed64b62",
   "metadata": {},
   "source": [
    "#### **Correct spelling of a *word***\n",
    "It corrects _simple spelling mistakes_ as a repeated character and fat finger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633fbbab-76cc-4605-89e7-4cf744eb63e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24837b03-8be5-4d87-9884-6022b1250997",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_be_corrected = 'appple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce434e-6517-429f-9e63-25a002aee0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b82ff65-2c29-4bbd-b02e-13c3448e1b47",
   "metadata": {},
   "source": [
    "#### **Correct spelling of a _sentence_***\n",
    "**`TextBlob()`** is a simple text block representation from the `textblob` library which has many useful methods, especially for **correcting the spelling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49404fa5-ce40-4586-8b9b-a82a315f2d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdaffb-2126-4de6-9ee9-968b7c16a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_be_corrected = 'A sentencee to checkk!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc90472-19fc-425c-aa01-14b2cbdffa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a58805-9d7c-405b-961d-231ac46d77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cafafd-c18a-4ed0-adfa-437f265885fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spelling correction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccfbc49-4935-4474-a7f9-4d180e2f7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e28312-1134-4782-bce4-178488685605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea86d2-ee8e-4a8e-ba73-13df699a74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping function to perform spelling correction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275561e4-d74f-48ea-a223-04c82fa01ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My favorit team is Barcelonah, they got sum amazin playas who can do all sortz of trickz with the balll.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439bd93-d6cf-472f-932f-0387cf055dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_correction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5f786-5467-4453-92ff-2e21b964ecab",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Note that the **spelling corrector _is not perfect_** but it helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1dc7f-ef60-4a19-837a-bc18e65f7ea2",
   "metadata": {},
   "source": [
    "### 3.5. Expand Contractions\n",
    "- To remove **stop words** in the next step, it is crucial that we deal with ***contractions*** first.\n",
    "- _Contractions_ are shorthand forms for words like _do not_ (***don‚Äôt***), _would not_ (***wouldn‚Äôt***), _it is_ (***it's***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46b86b-4d5a-4dfe-8289-ffa07bbb1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f5ec4d-be77-4b7c-bbe3-7403c60bfe88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04df21-fce9-4de9-bc87-dbfd0b72f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ain't, aren't, can't, cause, can't've\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e46b7e-2565-47b5-84b6-f2ab798439fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_contractions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe49646-48a1-4e49-b449-804a443e7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm gonna tell you a little story about a guy who loved to travel. He'd go to all sorts of places, from big cities to small towns, and he'd always find something interesting to see or do. Sometimes he'd go with friends, but most of the time he'd go alone. That didn't bother him though, because he liked the freedom of being able to go wherever he wanted without having to worry about anyone else's schedule. And let me tell you, he saw some amazing things. From the top of mountains to the depths of the ocean, he saw it all. And he wouldn't have traded those experiences for anything.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf94980-fae1-4ecc-a3ac-6dd9e7fbc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_contractions(text, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e16f6f-a2ac-4762-be75-81426bb4a72f",
   "metadata": {},
   "source": [
    "### 3.6. Remove _Stop Words_\n",
    "- Some of the **frequently used words** __are not particularly **useful**_ for some NLP tasks, for example, _tokenization_, _text classification_, _text summarization_, or any similar task.\n",
    "- In English, some examples of those words are: \"such as a, an, the, of, in, ...\"\n",
    "- These words, called **stop words**, don't don‚Äôt carry any content on their own.\n",
    "- **Stop words** are typically (though not always) _removed_ from further analysis in some NLP problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036cf3d-bcbe-406f-ab8e-49f38c154f9f",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918578a4-fbfd-454a-875c-c2005eb6fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c8bfc-8916-4875-98b0-1b02938a55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/hisamuka/nltk_data/corpora/stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0cfec-4f00-4aeb-acd4-6913a1ece9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8fa6b6-1dd8-47bb-ab6c-aa32b69098e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7201dada-212e-4dc2-98c4-510696d611bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89aa72-c406-4847-bf37-ec7a248e6250",
   "metadata": {},
   "source": [
    "##### **Portuguese**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0357c5-7955-4370-8122-fe4d800b9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Este √© um texto incr√≠vel, o melhor texto que voc√™ ler√° hoje, te garanto.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8abde2f-848e-464a-875b-c4931849235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords(text, language='portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac48fb-fc0d-4783-ac9a-5de23cdc345e",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f38e95-3fca-46a7-8dfd-4053efb4bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd3dc3d-2dbc-432b-9b02-0ed2e3571aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181c0fbe-4830-411f-9c83-8dac845a630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aa8843-260d-460a-8772-436a87a22cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7fe8a-16f5-4ae2-adbd-a42cda464b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9086f-ebb3-4b4f-aaca-d451f5b319d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_spacy(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce5c04-3200-40ff-8e13-49a15025ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_spacy_2(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cb890-7682-4b5b-9c94-bb138783cfe5",
   "metadata": {},
   "source": [
    "### 3.7. Stemming and Lemmatization\n",
    "\n",
    "<img src='./imgs/stemming_vs_lemmatization.png' /> <br/>\n",
    "Source: https://www.kaggle.com/getting-started/186152\n",
    "\n",
    "<img src='./imgs/stemming_vs_lemmatization_2.png' /> <br/>\n",
    "Source: https://www.quora.com/What-is-difference-between-stemming-and-lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25fca4-3669-40e6-aaad-a056e7170a80",
   "metadata": {},
   "source": [
    "#### **Stemming**\n",
    "- Refers to the process of **removing suffixes and reducing a word to some *base (stem)*** form such that all different variants of that word can be represented by the _same form_..\n",
    "- The words obtained (_stems_) are not guaranteed to exist, which can be a problem depending on what we are solving.\n",
    "- **Porter Stemmer** and **Snowball Stemmer** are popular _stemming algorithms_ included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009eeb1-4ac1-4bea-bd64-eb0e06c2bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['develop', 'developed', 'developing', 'development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dd077-5ae7-4d25-885d-df1e750ac195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f631f9-9277-479a-aa2d-d668703746e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899219b3-8133-4f4f-acd5-dca283bed126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9925a51-d15b-4ec4-a117-5e55eefe9227",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = snow_stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861488b-ba8b-4793-ba61-d1304c6d171d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Portuguese**\n",
    "- **RSLPStemmer** is a popular _stemming algorithm_ designed for **Portuguese**, which is also included in NLTK.\n",
    "- We can also use **Snowball Stemmer** for _Portuguese_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66977-65d5-4267-81d9-90c689f6478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['amigo', 'amizade', 'amigas', 'amig√£o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bf8a0b-f9b8-4eb8-b706-6cf6f5955630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSLPStemmer\n",
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926485d-d3a0-49ea-83ba-129c941e179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd5e1eb-608e-4e0b-b294-9af557a26e62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb514aad-8431-42d0-8f68-95a4828f8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec27be0-7eff-4fb0-9113-aba4898cad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a4816-6101-41d2-8f68-5f9a8c7d6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = snow_stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcd790-ab9d-4c8d-a2b1-a1677bce76ac",
   "metadata": {},
   "source": [
    "#### **Lemmatization**\n",
    "- The process of ***mapping* all the different forms of a word to its *base word (lemma)***.\n",
    "- Requires more _linguistic knowledge_ than _stemming_.\n",
    "- **WordNet** is a popular lemmatization algorithm_ included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806cd18b-1c08-41fd-a18c-4b2f0c48fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['drive', 'drives', 'drove', 'driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28df257-b3fb-4a50-8c5a-78ed046359b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the lemmas\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4302f06-2c76-4cfd-8724-1e768c6b71a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695ae5ec-b575-464e-9d07-749e2ea54aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    # pos='v' means the word to be analyzed is a verb\n",
    "    # we need to be explicit here\n",
    "    # there are other options: e.g., 'a' for adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebee451-5ed5-4c8f-a7fb-20696c4eee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization for an adjective\n",
    "print(lemmatizer.lemmatize('better', pos='a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964276b-383d-48e1-ad5e-1eecb85b126e",
   "metadata": {},
   "source": [
    "#### **Stemming and Lemmatization** in `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079858d-b075-4328-aa84-4fd3476675eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7cbab-bf4a-4a63-9c9c-b0f42f503569",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7e09d7-69ea-4b0f-8cfd-3e3184bf2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2f192-c724-4f94-b1d3-5815b4d8ac19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d62df-8d99-4e88-acee-f7640a2693bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['drive', 'drives', 'drove', 'driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9825665f-d0e1-47a2-a912-37afe889f610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21376023-60fe-4453-a407-e7fa738d354b",
   "metadata": {},
   "source": [
    "##### **Portuguese**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b106a-1492-4252-9f80-845bda846f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090efad3-0158-4dd2-885b-cc5ec5c2b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['amigo', 'amizade', 'amigas', 'amig√£o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12324fe-0378-4506-bbfd-5e5ace495e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09dd52-3e53-4bc9-af62-15720ce32a2d",
   "metadata": {},
   "source": [
    "### 3.8. Part-Of-Speech (POS) Tagging\n",
    "- Also called ***grammatical tagging***, it is the _automatic assignment_ of **POS tags** to _words_ in a sentence.\n",
    "- A **POS** is a _grammatical_ classification that commonly includes verbs, adjectives, adverbs, nouns, etc.\n",
    "- **POS tags** make it possible for _automatic text processing tools_ to take into account which part of speech each word is.\n",
    "- This facilitates the use of linguistic criteria in addition to statistics.\n",
    "- For languages where the same word can have different parts of speech, e.g. work in English, **POS tags** are used to distinguish between the occurrences of the word when used as a noun or verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fd5c2-26a5-45fd-bf29-9c0ae8c51ede",
   "metadata": {},
   "source": [
    "#### View token tags\n",
    "Recall that you can obtain a particular token by its index position.\n",
    "* To view the coarse POS tag use `token.pos_`\n",
    "* To view the fine-grained tag use `token.tag_`\n",
    "* To view the description of either type of tag use `spacy.explain(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cf1ae5-61d4-4a91-be6b-cbc18d0000ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bill = \"Bill Gates is an American entrepreneur and philanthropist who co-founded Microsoft Corporation in 1975.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117cea6-0258-426a-9413-89f23b8e2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ca410-68fc-4a1e-83fc-e23d1141fd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(text_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69484071-8b8d-47ef-bc3b-347b21b867ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Word           | POS tag  | Tag    | Explanation POS')\n",
    "print(f'---------------|----------|--------|----------------')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:14} | {token.pos_:{8}} | {token.tag_:{6}} | {spacy.explain(token.pos_):{14}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637ff69-380a-4e5e-9864-fee7aa6cfe5e",
   "metadata": {},
   "source": [
    "#### Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600eae0-fb9c-4881-aa16-30132a5dc9c0",
   "metadata": {},
   "source": [
    "___\n",
    "## Fine-grained Part-of-speech Tags\n",
    "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
    "<table>\n",
    "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a442f6-13c7-4daa-a3d9-b4f8c378bddd",
   "metadata": {},
   "source": [
    "#### Visualizing Parts of Speech\n",
    "spaCy offers an outstanding visualizer called **displaCy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e929ca8-ea94-4fad-94fe-7cbc5deb6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the displaCy library\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9efd00-b729-47d7-863a-6ec1825d4873",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86779fd4-862c-412c-aae3-95c67a0e3af1",
   "metadata": {},
   "source": [
    "#### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f4888-c88f-4faa-92b5-682dadf3aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mau = 'Maur√≠cio de Sousa √© o criador da Turma da M√¥nica, uma s√©rie de gibis brasileiros que foi criada em 1959.'\n",
    "text_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23869281-b876-4468-9559-d7649a0527d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary\n",
    "\n",
    "doc = nlp(text_mau)\n",
    "\n",
    "print(f'Word           | POS tag  | Explanation POS | Tag    ')\n",
    "print(f'---------------|----------|-----------------|----------------')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:14} | {token.pos_:{8}} | {spacy.explain(token.pos_):{15}} | {token.tag_:{6}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4caecb-879b-4034-acc8-b7df6fee063c",
   "metadata": {},
   "source": [
    "### 3.9. Named-Entity Recognition (NER)\n",
    "- **NER** tries to find out whether or not a word is a ***named entity***.\n",
    "- ***Named entities*** are persons, locations, organizations, time expressions etc.\n",
    "- This problem can be broken down into _detection of names_ followed by _classification of name_ into the corresponding categories.\n",
    "- Most often a word recognized by **NER** may be recognized as a ***noun*** by a _POS tagger_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d02f0-8b81-4a19-9392-392d248fa6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f19f32e-f123-4dbc-a941-c8fd31264c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce5973-4171-43fb-a12e-554799ae8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e44d7f-031b-41c3-8149-8bbfeb46bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word                   | NER           | Explanation')\n",
    "print(f'-----------------------|---------------|-------------------------------')\n",
    "\n",
    "# Print the named entities in the text\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:22} | {ent.label_:13} | {spacy.explain(ent.label_):30}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edfc1b-c1ae-4396-8167-4eaf1a0cd633",
   "metadata": {},
   "source": [
    "#### Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab38681-38c6-4dd8-b1c8-d4b593edbc41",
   "metadata": {},
   "source": [
    "We can **extend the *NER*** library in `spaCy`:\n",
    "- https://towardsdatascience.com/extend-named-entity-recogniser-ner-to-label-new-entities-with-spacy-339ee5979044"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657612e-3b7e-401d-87b7-dc09061ef7b8",
   "metadata": {},
   "source": [
    "#### Visualizing NER\n",
    "- https://spacy.io/usage/visualizers#ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d8512-a80a-4bb3-9b37-f8b3a6c4f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654fb80-decb-4e5a-af52-f9b426cb3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d287b91-37d6-4a37-b06e-1915694c0503",
   "metadata": {},
   "source": [
    "#### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76157beb-7ba6-46ec-a25a-c6477b4dde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07ea52-34f8-416a-9af7-5a82fe022c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea5878-153d-4a2b-b53c-0d7e59ff4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text_mau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a67d409-efb5-48cb-8764-c124b8a20ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Word                   | NER           | Explanation')\n",
    "print(f'-----------------------|---------------|-------------------------------')\n",
    "\n",
    "# Print the named entities in the text\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:22} | {ent.label_:13} | {spacy.explain(ent.label_):30}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f3d06-9c8c-4073-87b2-9a2b2ef43ef3",
   "metadata": {},
   "source": [
    "The year **wasn't** identified as a **NER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d95f8-2576-4d2b-a890-b6e4bf1bc7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e94daa-39b0-477c-8c8c-1be2048deea3",
   "metadata": {},
   "source": [
    "## See more:\n",
    "- https://www.alura.com.br/artigos/lemmatization-vs-stemming-quando-usar-cada-uma\n",
    "- https://www.askpython.com/python/examples/pos-tagging-in-nlp-using-spacy\n",
    "- https://towardsdatascience.com/text-preprocessing-in-natural-language-processing-using-python-6113ff5decd8\n",
    "- https://medium.com/product-ai/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
