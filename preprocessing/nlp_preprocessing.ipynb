{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3439ed4a-df0a-45d9-834a-e1f1f43b0280",
   "metadata": {},
   "source": [
    "## **D3TOP - T√≥picos em Ci√™ncia de Dados (IFSP Campinas)**\n",
    "**Prof. Dr. Samuel Martins (@iamsamucoding @samucoding @xavecoding)** <br/>\n",
    "xavecoding: https://youtube.com/c/xavecoding <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b27a0ea-69c6-424d-88ad-0782fe5366b9",
   "metadata": {},
   "source": [
    "# NLP Text Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43af6e-102a-496e-9a17-43ae78225aaf",
   "metadata": {},
   "source": [
    "We are going to see several steps/methods used **to clean and preprocess *text data***. <br/>\n",
    "**NOT all** of these steps are _always necessary_, and ***not all*** of them are performed in the order in which we will present here.\n",
    "\n",
    "Inicially, we are going to see some popular **NLP packages** and its differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322326fe-ac96-4dd6-b3d9-f4c5202b9232",
   "metadata": {},
   "source": [
    "## 1. NLP Packages\n",
    "- NLTK: https://www.nltk.org/\n",
    "- spaCy: https://spacy.io/\n",
    "- BeautifulSoup4: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d11a748-6a35-4661-9c8a-76087e51c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/hisamuka/yeah/lib/python3.8/site-packages (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: joblib in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk) (8.0.1)\n",
      "Requirement already satisfied: tqdm in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: spacy in /home/hisamuka/yeah/lib/python3.8/site-packages (2.3.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (44.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy) (1.20.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/hisamuka/yeah/lib/python3.8/site-packages (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74758d-1bca-49c2-9188-aeff642e67de",
   "metadata": {},
   "source": [
    "### Natural Language Toolkit (NLTK)\n",
    "- Popular NLP open source package\n",
    "- Released in 2011\n",
    "- Provides many functinalities to treat and process _text data_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2c9943-eb80-42af-aa98-2b546ccc0fe8",
   "metadata": {},
   "source": [
    "### SpaCy\n",
    "- Open Source Natural Language Processing Library\n",
    "- Designed to _efficiently_ execute popular algorithms and tackle NLP tasks with maximum _effectiveness_.\n",
    "- SpaCy typically offers _only one_ implemented approach for various NLP tasks, selecting **the most efficient algorithm** that is currently available.\n",
    "- Thus, we cannot choose other algorithms for a given NLP task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ab2707-979e-47e3-9dc8-b47d06ee1c52",
   "metadata": {},
   "source": [
    "### NLTK vs SpaCy\n",
    "- In general, SpaCy is considerably **faster and more efficient** than NLTK.\n",
    "- In turn, NLTK provides **pre-trained models** for some applications, such as _sentiment analysis_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e39b0-31ab-46a6-a419-ac9d06e69e20",
   "metadata": {},
   "source": [
    "### 1.1 Dive into SpaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7302cc-8334-44b8-aa9a-da02f50ef9b0",
   "metadata": {},
   "source": [
    "#### Loading SpaCy for a given Language\n",
    " - **English:** https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263a2198-5a64-4a80-9cbb-326a6e5b19d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en_core_web_sm==2.3.1\n",
      "  Using cached en_core_web_sm-2.3.1-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (44.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.59.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.6)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.20.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m‚úî Linking successful\u001b[0m\n",
      "/home/hisamuka/yeah/lib/python3.8/site-packages/en_core_web_sm -->\n",
      "/home/hisamuka/yeah/lib/python3.8/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c60f80b-73de-46b7-a72f-225bdeb6ea57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab86227-13c1-4d5e-a927-c16d4bfb24c1",
   "metadata": {},
   "source": [
    "- **Portuguese:** https://spacy.io/models/pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a22831c-b021-4d15-b730-c1f5c402e403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.3.0/pt_core_news_sm-2.3.0.tar.gz#egg=pt_core_news_sm==2.3.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pt_core_news_sm==2.3.0\n",
      "  Using cached pt_core_news_sm-2.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from pt_core_news_sm==2.3.0) (2.3.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (0.8.2)\n",
      "Requirement already satisfied: setuptools in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (44.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.20.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (7.4.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/hisamuka/yeah/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (4.59.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->pt_core_news_sm==2.3.0) (1.26.3)\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n",
      "\u001b[38;5;2m‚úî Linking successful\u001b[0m\n",
      "/home/hisamuka/yeah/lib/python3.8/site-packages/pt_core_news_sm -->\n",
      "/home/hisamuka/yeah/lib/python3.8/site-packages/spacy/data/pt\n",
      "You can now load the model via spacy.load('pt')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cc4c26-269b-4cf5-afe4-6121860853c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66f185-3645-4bfb-b1df-d57ba617fc51",
   "metadata": {},
   "source": [
    "#### SpaCy (Preprocessing) Pipeline\n",
    "SpaCy works with a _Pipeline object_.\n",
    "\n",
    "<img src='./imgs/spacy_pipeline.png' width=600 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe01f1-5edd-4c14-b0d4-b5f4896fd3f9",
   "metadata": {},
   "source": [
    "From [official documentation](https://spacy.io/usage/spacy-101#pipelines):\n",
    "- When you call `nlp` on a _text_, spaCy first **tokenizes** the _text_ to produce a `Doc object`.\n",
    "- The `Doc` is then processed in several different steps ‚Äì this is also referred to as the **processing pipeline**.\n",
    "- The pipeline used by the _trained pipelines_ typically include a `tagger`, a `lemmatizer`, a `parser` and an `entity recognizer`.\n",
    "- Each pipeline component returns the **processed `Doc`**, which is then passed on to the next component.\n",
    "\n",
    "<img src='./imgs/spacy_pipeline_table.png' width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb1a21-79ce-4b8b-8467-981213d20329",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6878028c-9bd8-4643-9f6e-0d42446654e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sun is a massive, luminous ball of gas that is the center of our solar system. It is estimated to be around 4.6 billion years old and has a diameter of about 1.39 million kilometers. The sun's energy is produced through a process called nuclear fusion, where hydrogen atoms combine to form helium and release a tremendous amount of energy in the process.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The sun is a massive, luminous ball of gas that is the center of our solar system. It is estimated to be around 4.6 billion years old and has a diameter of about 1.39 million kilometers. The sun's energy is produced through a process called nuclear fusion, where hydrogen atoms combine to form helium and release a tremendous amount of energy in the process.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcfdd27-ca1a-490c-a46f-6416f2fb1dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cc4a209-d357-4a3e-8168-4cba929b9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f6308a-9ff7-4ce7-b92d-5a44a72e0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d0b8467-eac5-4a89-8c91-8b94ab34208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The sun is a massive, luminous ball of gas that is the center of our solar system. It is estimated to be around 4.6 billion years old and has a diameter of about 1.39 million kilometers. The sun's energy is produced through a process called nuclear fusion, where hydrogen atoms combine to form helium and release a tremendous amount of energy in the process.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full text\n",
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d487321e-2e1e-4347-8f98-6a241e709258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# language of the document\n",
    "doc.lang_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2140ed73-e4d7-4828-be16-c610ea299121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# for each token/word\n",
    "for token in doc:\n",
    "    print(type(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f04c7a6e-4614-4ee9-ab03-5f0bea2e9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The the DET Xxx True True\n",
      "sun sun NOUN xxx True False\n",
      "is be AUX xx True True\n",
      "a a DET x True True\n",
      "massive massive ADJ xxxx True False\n",
      ", , PUNCT , False False\n",
      "luminous luminous ADJ xxxx True False\n",
      "ball ball NOUN xxxx True False\n",
      "of of ADP xx True True\n",
      "gas gas NOUN xxx True False\n",
      "that that DET xxxx True True\n",
      "is be AUX xx True True\n",
      "the the DET xxx True True\n",
      "center center NOUN xxxx True False\n",
      "of of ADP xx True True\n",
      "our -PRON- DET xxx True True\n",
      "solar solar ADJ xxxx True False\n",
      "system system NOUN xxxx True False\n",
      ". . PUNCT . False False\n",
      "It -PRON- PRON Xx True True\n",
      "is be AUX xx True True\n",
      "estimated estimate VERB xxxx True False\n",
      "to to PART xx True True\n",
      "be be AUX xx True True\n",
      "around around ADP xxxx True True\n",
      "4.6 4.6 NUM d.d False False\n",
      "billion billion NUM xxxx True False\n",
      "years year NOUN xxxx True False\n",
      "old old ADJ xxx True False\n",
      "and and CCONJ xxx True True\n",
      "has have AUX xxx True True\n",
      "a a DET x True True\n",
      "diameter diameter NOUN xxxx True False\n",
      "of of ADP xx True True\n",
      "about about ADP xxxx True True\n",
      "1.39 1.39 NUM d.dd False False\n",
      "million million NUM xxxx True False\n",
      "kilometers kilometer NOUN xxxx True False\n",
      ". . PUNCT . False False\n",
      "The the DET Xxx True True\n",
      "sun sun NOUN xxx True False\n",
      "'s 's PART 'x False True\n",
      "energy energy NOUN xxxx True False\n",
      "is be AUX xx True True\n",
      "produced produce VERB xxxx True False\n",
      "through through ADP xxxx True True\n",
      "a a DET x True True\n",
      "process process NOUN xxxx True False\n",
      "called call VERB xxxx True False\n",
      "nuclear nuclear ADJ xxxx True False\n",
      "fusion fusion NOUN xxxx True False\n",
      ", , PUNCT , False False\n",
      "where where ADV xxxx True True\n",
      "hydrogen hydrogen NOUN xxxx True False\n",
      "atoms atom NOUN xxxx True False\n",
      "combine combine VERB xxxx True False\n",
      "to to PART xx True True\n",
      "form form VERB xxxx True False\n",
      "helium helium NOUN xxxx True False\n",
      "and and CCONJ xxx True True\n",
      "release release VERB xxxx True False\n",
      "a a DET x True True\n",
      "tremendous tremendous ADJ xxxx True False\n",
      "amount amount NOUN xxxx True True\n",
      "of of ADP xx True True\n",
      "energy energy NOUN xxxx True False\n",
      "in in ADP xx True True\n",
      "the the DET xxx True True\n",
      "process process NOUN xxxx True False\n",
      ". . PUNCT . False False\n"
     ]
    }
   ],
   "source": [
    "# for each token/word\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774bfba7-cd40-4073-822a-286b877bd677",
   "metadata": {},
   "source": [
    "## üßπ 2. Text Cleaning\n",
    "- actions of removing something\n",
    "- we can perform some preprocessing before it (e.g., lowering text)\n",
    "\n",
    "Methods presented here:\n",
    "1. Remove newlines `\\n` and Tabs `\\t`\n",
    "2. Strip HTML Tags\n",
    "3. Remove links\n",
    "4. Remove extra whitespaces\n",
    "5. Unicode Normalization\n",
    "6. Removing Emojis\n",
    "7. Removing Punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a74e4-5d71-4ca5-8697-a80263e1f348",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Remove newlines `\\n` and Tabs `\\t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3771b76b-3352-4c9e-87b1-c829fd07d944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_newlines_tabs = \\\n",
    "\"\"\"Cats are fascinating creatures that have captured the hearts of humans for centuries. They are known for their agility, grace, and independence, and their ability to make us laugh and feel comforted. \\n\n",
    "\n",
    "\\tDespite their reputation for being aloof, cats are actually quite social animals and thrive on attention and affection from their owners. They are also highly intelligent and can be trained to do a variety of tricks and behaviors, including using a litter box and walking on a leash. \\n\n",
    "\n",
    "\\tOne of the most endearing things about cats is their tendency to curl up in cozy spots, whether it's a sunny windowsill, a soft bed, or a warm lap. They are also famous for their love of napping, and can often be found snoozing for hours on end. \\n\n",
    "\n",
    "\\tWhile cats may sometimes get a bad rap for being aloof or indifferent, those who have experienced the joy of sharing their lives with a feline friend know that there's nothing quite like the bond between a cat and its human.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4224aed2-4ab4-412e-ac43-ad914f1712c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats are fascinating creatures that have captured the hearts of humans for centuries. They are known for their agility, grace, and independence, and their ability to make us laugh and feel comforted. \n",
      "\n",
      "\n",
      "\tDespite their reputation for being aloof, cats are actually quite social animals and thrive on attention and affection from their owners. They are also highly intelligent and can be trained to do a variety of tricks and behaviors, including using a litter box and walking on a leash. \n",
      "\n",
      "\n",
      "\tOne of the most endearing things about cats is their tendency to curl up in cozy spots, whether it's a sunny windowsill, a soft bed, or a warm lap. They are also famous for their love of napping, and can often be found snoozing for hours on end. \n",
      "\n",
      "\n",
      "\tWhile cats may sometimes get a bad rap for being aloof or indifferent, those who have experienced the joy of sharing their lives with a feline friend know that there's nothing quite like the bond between a cat and its human.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cat_text_newlines_tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048754aa-bd05-4c85-9c56-0386b75bbe5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cats are fascinating creatures that have captured the hearts of humans for centuries. They are known for their agility, grace, and independence, and their ability to make us laugh and feel comforted. \\n\\n\\n\\tDespite their reputation for being aloof, cats are actually quite social animals and thrive on attention and affection from their owners. They are also highly intelligent and can be trained to do a variety of tricks and behaviors, including using a litter box and walking on a leash. \\n\\n\\n\\tOne of the most endearing things about cats is their tendency to curl up in cozy spots, whether it's a sunny windowsill, a soft bed, or a warm lap. They are also famous for their love of napping, and can often be found snoozing for hours on end. \\n\\n\\n\\tWhile cats may sometimes get a bad rap for being aloof or indifferent, those who have experienced the joy of sharing their lives with a feline friend know that there's nothing quite like the bond between a cat and its human.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_text_newlines_tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fcc4530-2908-4585-b5d4-91c115891f5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_newlines_tabs(text):\n",
    "    regex = '[\\\\n\\\\t]'  # \\n or \\t\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "68960355-64d5-49d5-9d9e-3b4937ecbce2",
   "metadata": {
    "tags": []
   },
   "source": [
    "remove_newlines_tabs(cat_text_newlines_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8f1a9-42fe-4085-b2a2-9a9e7bbef2df",
   "metadata": {},
   "source": [
    "### 2.2. Strip HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fabac21-7a1b-4a64-8da5-273479f12ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_html_text = '''<p><i><b>Harry Potter and the Philosopher's Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy novel\">fantasy novel</a> written by British author <a href=\"/wiki/J._K._Rowling\" title=\"J. K. Rowling\">J. K. Rowling</a>. The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry Potter\">Harry Potter</a></i> series and Rowling's <a href=\"/wiki/Debut_novel\" title=\"Debut novel\">debut novel</a>, it follows <a href=\"/wiki/Harry_Potter_(character)\" title=\"Harry Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a>. Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione Granger\">Hermione Granger</a>, he faces an attempted comeback by the dark wizard <a href=\"/wiki/Lord_Voldemort\" title=\"Lord Voldemort\">Lord Voldemort</a>, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\n",
    "</p>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9e873d-f486-40ba-a4e7-739f5043036c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p><i><b>Harry Potter and the Philosopher's Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy novel\">fantasy novel</a> written by British author <a href=\"/wiki/J._K._Rowling\" title=\"J. K. Rowling\">J. K. Rowling</a>. The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry Potter\">Harry Potter</a></i> series and Rowling's <a href=\"/wiki/Debut_novel\" title=\"Debut novel\">debut novel</a>, it follows <a href=\"/wiki/Harry_Potter_(character)\" title=\"Harry Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a>. Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione Granger\">Hermione Granger</a>, he faces an attempted comeback by the dark wizard <a href=\"/wiki/Lord_Voldemort\" title=\"Lord Voldemort\">Lord Voldemort</a>, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "print(hp_html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b412123-a398-417e-bf97-ff4c6c8c23bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    \n",
    "    # Get all the text other than html tags.\n",
    "    stripped_text = soup.get_text(separator='')\n",
    "    \n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5755574c-cd5b-415d-bce2-d14238008a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Philosopher's Stone is a 1997 fantasy novel written by British author J. K. Rowling. The first novel in the Harry Potter series and Rowling's debut novel, it follows Harry Potter, a young wizard who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to Hogwarts School of Witchcraft and Wizardry. Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, Ron Weasley and Hermione Granger, he faces an attempted comeback by the dark wizard Lord Voldemort, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strip_html_tags(hp_html_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ed06a7-ae0f-43d4-82c9-8480bb8a0328",
   "metadata": {},
   "source": [
    "### 2.3. Remove Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ea98bdb-13c9-46a4-881c-3ce89115bf3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_text_with_links = \\\n",
    "'''Cats are amazing animals that have been domesticated for thousands of years. They are beloved by many people for their adorable appearance, unique personalities, and entertaining antics. Cats are also known for their ability to form strong bonds with their human companions.\n",
    "If you're a cat lover looking for more information about these fascinating creatures, there are many resources available online. You can visit websites like http://www.catster.com/ to learn more about cat breeds, behavior, and health. For more in-depth information, check out https://www.vet.cornell.edu/departments-centers-and-institutes/cornell-feline-health-center, which offers comprehensive resources for cat owners and veterinarians.\n",
    "If you're interested in adopting a cat or finding a local shelter, petfinder.com/cats/ is a great resource. This website allows you to search for cats available for adoption in your area and provides helpful information about the adoption process.\n",
    "Whether you're a seasoned cat owner or simply a cat enthusiast, these websites can provide you with valuable information and resources to help you better understand and care for your feline friends.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d9b2a5-5efb-47cd-a6e5-93508dd2855c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats are amazing animals that have been domesticated for thousands of years. They are beloved by many people for their adorable appearance, unique personalities, and entertaining antics. Cats are also known for their ability to form strong bonds with their human companions.\n",
      "If you're a cat lover looking for more information about these fascinating creatures, there are many resources available online. You can visit websites like http://www.catster.com/ to learn more about cat breeds, behavior, and health. For more in-depth information, check out https://www.vet.cornell.edu/departments-centers-and-institutes/cornell-feline-health-center, which offers comprehensive resources for cat owners and veterinarians.\n",
      "If you're interested in adopting a cat or finding a local shelter, petfinder.com/cats/ is a great resource. This website allows you to search for cats available for adoption in your area and provides helpful information about the adoption process.\n",
      "Whether you're a seasoned cat owner or simply a cat enthusiast, these websites can provide you with valuable information and resources to help you better understand and care for your feline friends.\n"
     ]
    }
   ],
   "source": [
    "print(cat_text_with_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1377f8a8-788c-4d3f-9583-59e1377d80c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cats are amazing animals that have been domesticated for thousands of years. They are beloved by many people for their adorable appearance, unique personalities, and entertaining antics. Cats are also known for their ability to form strong bonds with their human companions.\\nIf you're a cat lover looking for more information about these fascinating creatures, there are many resources available online. You can visit websites like http://www.catster.com/ to learn more about cat breeds, behavior, and health. For more in-depth information, check out https://www.vet.cornell.edu/departments-centers-and-institutes/cornell-feline-health-center, which offers comprehensive resources for cat owners and veterinarians.\\nIf you're interested in adopting a cat or finding a local shelter, petfinder.com/cats/ is a great resource. This website allows you to search for cats available for adoption in your area and provides helpful information about the adoption process.\\nWhether you're a seasoned cat owner or simply a cat enthusiast, these websites can provide you with valuable information and resources to help you better understand and care for your feline friends.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_text_with_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4f52873-bd45-4014-9ed6-d4081b5fe399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    regex_http = '((h|H)(t|T)(t|T)(p|P))\\S+'\n",
    "    regex_dot_com = '(\\s\\S+\\.com\\S*)'\n",
    "    regex = regex_http + '|' + regex_dot_com\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53b4dedb-b10e-46b5-8545-19c3bf25b8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Cats are amazing animals that have been domesticated for thousands of years. They are beloved by many people for their adorable appearance, unique personalities, and entertaining antics. Cats are also known for their ability to form strong bonds with their human companions.\\nIf you're a cat lover looking for more information about these fascinating creatures, there are many resources available online. You can visit websites like to learn more about cat breeds, behavior, and health. For more in-depth information, check out  which offers comprehensive resources for cat owners and veterinarians.\\nIf you're interested in adopting a cat or finding a local shelter, is a great resource. This website allows you to search for cats available for adoption in your area and provides helpful information about the adoption process.\\nWhether you're a seasoned cat owner or simply a cat enthusiast, these websites can provide you with valuable information and resources to help you better understand and care for your feline friends.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_links(cat_text_with_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b9cbc2-3c35-4c9b-aec1-78cb6027269f",
   "metadata": {},
   "source": [
    "### 2.4. Remove extra whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69fbafa5-4918-4b5d-b199-67fe56a97c41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "venice_text = \\\n",
    "'''Venice           is a city unlike any other, built on a network of     canals and filled with historic architecture and     cultural treasures.    Its unique layout and beautiful surroundings      have made it a      top tourist destination, attracting millions of visitors    each year.        The city is home to many iconic     landmarks, such as the Rialto Bridge, St. Mark's Basilica,     and the Doge's     Palace, which offer a glimpse into Venice's     rich history and artistic legacy.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e228141c-691b-4226-a9bf-5aa319ca193d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Venice           is a city unlike any other, built on a network of     canals and filled with historic architecture and     cultural treasures.    Its unique layout and beautiful surroundings      have made it a      top tourist destination, attracting millions of visitors    each year.        The city is home to many iconic     landmarks, such as the Rialto Bridge, St. Mark's Basilica,     and the Doge's     Palace, which offer a glimpse into Venice's     rich history and artistic legacy.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venice_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c46e8063-3d3a-4af9-898f-4e5f677daa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespaces(text):\n",
    "    regex = '\\s{2,}'\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "04cdf3cb-9507-4e62-bc20-580808f06bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Veniceis a city unlike any other, built on a network ofcanals and filled with historic architecture andcultural treasures.Its unique layout and beautiful surroundingshave made it atop tourist destination, attracting millions of visitorseach year.The city is home to many iconiclandmarks, such as the Rialto Bridge, St. Mark's Basilica,and the Doge'sPalace, which offer a glimpse into Venice'srich history and artistic legacy.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_extra_whitespaces(venice_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef89301-c327-48fe-a223-70d143becd0a",
   "metadata": {},
   "source": [
    "### 2.5. Unicode Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98280ab3-dc77-49c9-afcd-b5a3036a4f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "salvador_text = \"Salvador is a city full of life, culture, and history üåáüé≠üè∞. From the beautiful beaches üåäüèñÔ∏è to the vibrant music and dance scene üíÉüï∫üé∂, there's never a dull moment in this exciting Brazilian city üáßüá∑.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "453bc130-5904-4d5d-a77f-c32fc553ea4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Salvador is a city full of life, culture, and history üåáüé≠üè∞. From the beautiful beaches üåäüèñÔ∏è to the vibrant music and dance scene üíÉüï∫üé∂, there's never a dull moment in this exciting Brazilian city üáßüá∑.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salvador_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac6cc76d-0916-4b9b-b174-0d3a0e7d504a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicode_normalization(text):\n",
    "    return text.encode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4407fae1-10b3-4ce9-8602-68eba6273053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Salvador is a city full of life, culture, and history \\xf0\\x9f\\x8c\\x87\\xf0\\x9f\\x8e\\xad\\xf0\\x9f\\x8f\\xb0. From the beautiful beaches \\xf0\\x9f\\x8c\\x8a\\xf0\\x9f\\x8f\\x96\\xef\\xb8\\x8f to the vibrant music and dance scene \\xf0\\x9f\\x92\\x83\\xf0\\x9f\\x95\\xba\\xf0\\x9f\\x8e\\xb6, there's never a dull moment in this exciting Brazilian city \\xf0\\x9f\\x87\\xa7\\xf0\\x9f\\x87\\xb7.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicode_normalization(salvador_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccff61-0a25-47a2-8e10-e35db0913616",
   "metadata": {},
   "source": [
    "### 2.6. Removing Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87133142-5d59-4a3a-805b-85bddb5aeb51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_emojis(text):\n",
    "    regex_emoticons = u\"\\U0001F600-\\U0001F64F\"\n",
    "    regex_symbols_pictographs = u\"\\U0001F300-\\U0001F5FF\"\n",
    "    regex_transport_map_symbols = u\"\\U0001F680-\\U0001F6FF\"\n",
    "    regex_flags_ios = u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "    \n",
    "    regex = f\"\\s+[{regex_emoticons}{regex_symbols_pictographs}{regex_transport_map_symbols}{regex_flags_ios}]+\"\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca17b68e-7bc0-4d36-a4ad-d29c7342d651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Salvador is a city full of life, culture, and history. From the beautiful beachesÔ∏è to the vibrant music and dance scene, there's never a dull moment in this exciting Brazilian city.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emojis(salvador_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d64fd6-5ac3-4f07-b50c-0a0cf4c7dc30",
   "metadata": {},
   "source": [
    "### 2.7. Removing Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "911cb86f-13c9-4c8a-9e18-b729b05c3b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!hi. wh?at is the weat[h[er lik?e. +#'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '!hi. wh?at is the weat[h[er lik?e. +#'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3bea4ea-a9cc-43fe-a6cb-4200bfc30f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    regex = '[^\\w\\s]'\n",
    "    \n",
    "    return re.sub(regex, '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a5a5fcb-3667-4a7e-b162-7d5a245b6ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi what is the weather like '"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punctuation(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20c357-da24-4d83-91fc-499422e7214d",
   "metadata": {},
   "source": [
    "## üõ† 3. Preprocessing\n",
    "\n",
    "<img src='./imgs/preprocessing_pipeline.png' width=600 />\n",
    "\n",
    "**Source:** Vajjala et al. (2020), 'Practical Natural Language Processing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ab324-1097-4e2f-b705-21077a85ccd9",
   "metadata": {},
   "source": [
    "### 3.1. Sentence segmentation\n",
    "- We can do **sentence segmentation** by _breaking up_ text into **sentences** at the appearance of _full stops_ and _question marks_.\n",
    "- However, there may be abbreviations, forms of addresses (Dr., Mr., etc.), or ellipses (...) that may break the simple rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa143a61-ce9c-46b5-934b-ad9d8a303fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_text = \\\n",
    "'''Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works. It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
    "\n",
    "One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text. This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
    "\n",
    "However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively. Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing. As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1aba0ad0-0887-406c-9d53-2cc39a592dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works. It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
      "\n",
      "One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text. This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
      "\n",
      "However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively. Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing. As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.\n"
     ]
    }
   ],
   "source": [
    "print(dl_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a48dc-f8c2-4301-af40-2f37e141e4e8",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e954896-fe25-4e4d-a6ef-7282d78048ac",
   "metadata": {},
   "source": [
    "**Punkt Sentence Tokenizer** - `nltk.tokenize.punkt module`\n",
    "- This **tokenizer** divides _a text_ into **a list of *sentences*** by using an _unsupervised algorithm_ to build a model for abbreviation words, collocations, and words that start sentences.\n",
    "- It **must** be _trained on a large collection of plaintext_ in the **target language** before it can be used.\n",
    "- The NLTK data package includes a pre-trained Punkt tokenizer for English.\n",
    "\n",
    "https://www.nltk.org/api/nltk.tokenize.punkt.html#module-nltk.tokenize.punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fec7990e-17b2-4509-b43e-e2dce5703c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hisamuka/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading the pre-trained tokenizers\n",
    "# download on: /home/your_user/nltk_data/tokenizers/punkt\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dff998b2-bee8-45d4-9e97-674048cadcd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show the (downloaded) available tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "faa03bbc-a39a-4b4d-96d2-a1bbbf52aca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "czech.pickle     french.pickle     polish.pickle      spanish.pickle\n",
      "danish.pickle    german.pickle     portuguese.pickle  swedish.pickle\n",
      "dutch.pickle     greek.pickle      \u001b[0m\u001b[01;34mPY3\u001b[0m/               turkish.pickle\n",
      "english.pickle   italian.pickle    README\n",
      "estonian.pickle  malayalam.pickle  russian.pickle\n",
      "finnish.pickle   norwegian.pickle  slovene.pickle\n"
     ]
    }
   ],
   "source": [
    "ls ~/nltk_data/tokenizers/punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cdfe42e7-6c55-4ec2-bba3-64a6dfa7d01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67b49a01-6c79-465f-bbb6-cf2c1a09fef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example 1 in English\n",
    "dl_sentences = sent_tokenize(dl_text, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e713d330-30c4-44b6-b72a-7f5b1cc37514",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dl_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7d621a5-0ead-4883-b7eb-5eeb2b6d5c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.\n",
      "01 - It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
      "02 - One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.\n",
      "03 - This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
      "04 - However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.\n",
      "05 - Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.\n",
      "06 - As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(dl_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "961f5744-a4be-4abc-9491-ad6f1e16797d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><i><b>Harry Potter and the Philosopher\\'s Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy novel\">fantasy novel</a> written by British author <a href=\"/wiki/J._K._Rowling\" title=\"J. K. Rowling\">J. K. Rowling</a>. The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry Potter\">Harry Potter</a></i> series and Rowling\\'s <a href=\"/wiki/Debut_novel\" title=\"Debut novel\">debut novel</a>, it follows <a href=\"/wiki/Harry_Potter_(character)\" title=\"Harry Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a>. Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione Granger\">Hermione Granger</a>, he faces an attempted comeback by the dark wizard <a href=\"/wiki/Lord_Voldemort\" title=\"Lord Voldemort\">Lord Voldemort</a>, who killed Harry\\'s parents, but failed to kill Harry when he was just 15 months old.\\n</p>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 2 (with HTML) in English\n",
    "hp_html_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45c4cf3f-ee49-41cf-a254-069c4dcd15aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_sentences = sent_tokenize(hp_html_text, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ec3fcf9-769a-4d3a-890d-c79db3d17c0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - <p><i><b>Harry Potter and the Philosopher's Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy novel\">fantasy novel</a> written by British author <a href=\"/wiki/J._K._Rowling\" title=\"J. K. Rowling\">J.\n",
      "01 - K. Rowling</a>.\n",
      "02 - The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry Potter\">Harry Potter</a></i> series and Rowling's <a href=\"/wiki/Debut_novel\" title=\"Debut novel\">debut novel</a>, it follows <a href=\"/wiki/Harry_Potter_(character)\" title=\"Harry Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a>.\n",
      "03 - Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione Granger\">Hermione Granger</a>, he faces an attempted comeback by the dark wizard <a href=\"/wiki/Lord_Voldemort\" title=\"Lord Voldemort\">Lord Voldemort</a>, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\n",
      "04 - </p>\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(hp_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c0798c-f89a-42af-9214-b5982fd47446",
   "metadata": {},
   "source": [
    "**Tokenizer doesn't** deal with HTML tags. See the last segmented sentence, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c8b97-3d0a-4d8c-b990-7429402fc363",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88ffd4b5-b10e-49ee-a4aa-169b8951544a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59f3f479-e37c-4842-bdc8-6a9dd13c4bf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(dl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b5b96f-87d5-4018-82fa-df9af540f32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl_sentences_spacy = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8aa6a1e4-d574-4046-97cd-ed73296d0aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.\n",
      "01 - It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
      "\n",
      "\n",
      "02 - One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.\n",
      "03 - This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
      "\n",
      "\n",
      "04 - However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.\n",
      "05 - Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.\n",
      "06 - As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(dl_sentences_spacy):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fa6d56-e035-4e92-bf1a-ba07e73d6b0f",
   "metadata": {},
   "source": [
    "`SpaCy` keeps the `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f5b22e5-77c6-4589-bb75-ab7cb7aa7f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - <p><i><b\n",
      "01 - >Harry Potter and the Philosopher's Stone</b></i> is a 1997 <a href=\"/wiki/Fantasy_novel\" class=\"mw-redirect\" title=\"Fantasy\n",
      "02 - novel\">fantasy\n",
      "03 - novel</a\n",
      "04 - > written by British author <a href=\"/wiki/J._K._Rowling\n",
      "05 - \" title=\"J. K. Rowling\">J. K. Rowling</a\n",
      "06 - >.\n",
      "07 - The first novel in the <i><a href=\"/wiki/Harry_Potter\" title=\"Harry\n",
      "08 - Potter\">Harry Potter</a></i> series and Rowling's <\n",
      "09 - a href=\"/wiki/Debut_novel\"\n",
      "10 - title=\"Debut\n",
      "11 - novel\">debut\n",
      "12 - novel</a\n",
      "13 - >, it follows <a href=\"/wiki/Harry_Potter_(character)\n",
      "14 - \" title=\"Harry\n",
      "15 - Potter (character)\">Harry Potter</a>, a young <a href=\"/wiki/Wizard_(fantasy)\" class=\"mw-redirect\" title=\"Wizard\n",
      "16 - (fantasy)\">wizard</a> who discovers his magical heritage on his eleventh birthday, when he receives a letter of acceptance to <a href=\"/wiki/Hogwarts_School_of_Witchcraft_and_Wizardry\" class=\"mw-redirect\" title=\"Hogwarts School of Witchcraft and Wizardry\">Hogwarts School of Witchcraft and Wizardry</a\n",
      "17 - >.\n",
      "18 - Harry makes close friends and a few enemies during his first year at the school and with the help of his friends, <a href=\"/wiki/Ron_Weasley\" title=\"Ron Weasley\">Ron Weasley</a> and <a href=\"/wiki/Hermione_Granger\" title=\"Hermione\n",
      "19 - Granger\">Hermione Granger</a\n",
      "20 - >, he faces an attempted comeback by the dark wizard <\n",
      "21 - a href=\"/wiki/Lord_Voldemort\" title=\"Lord\n",
      "22 - Voldemort\">Lord Voldemort</a>, who killed Harry's parents, but failed to kill Harry when he was just 15 months old.\n",
      "\n",
      "23 - </p>\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(hp_html_text)\n",
    "\n",
    "hp_sentences_spacy = [sent.text for sent in doc.sents]\n",
    "\n",
    "for i, sentence in enumerate(hp_sentences_spacy):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86b3d89-4306-496d-a5ed-2de0c98b6542",
   "metadata": {},
   "source": [
    "**`SpaCy` doesn't** deal with HTML tags. See the last segmented sentence, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60d237-9c91-4ace-bcf1-cb102664c126",
   "metadata": {},
   "source": [
    "#### **Portuguese**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a304fd54-1c76-4dbb-8075-65c8faaf0c43",
   "metadata": {},
   "source": [
    "##### **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe52ac48-c013-4530-8bfa-8aceb39d5a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suco_text = \\\n",
    "'''Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante. Rico em vitamina C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\n",
    "\n",
    "Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado. Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\n",
    "\n",
    "Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano. Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6eb0f15-44b3-4b83-a692-19cf3d859f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante. Rico em vitamina C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\n",
      "\n",
      "Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado. Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\n",
      "\n",
      "Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano. Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.\n"
     ]
    }
   ],
   "source": [
    "print(suco_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4679c956-5b72-4189-bef5-37975fc79929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "suco_sentences = sent_tokenize(suco_text, language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7519bfd-e525-4729-be49-76f1e9367a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante.\n",
      "01 - Rico em vitamina C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\n",
      "02 - Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado.\n",
      "03 - Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\n",
      "04 - Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano.\n",
      "05 - Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(suco_sentences):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54710e71-8dec-4da3-b151-dab8a1d872ea",
   "metadata": {},
   "source": [
    "##### **SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a5e5720-0cca-4843-9dc6-1ce15d208c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24a570c6-d0de-42d4-b343-e59aecb0da1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc = nlp(suco_text)\n",
    "\n",
    "suco_sentences_spacy = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "994b6cd5-c775-4adc-9a5d-f8eed456f873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 - Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante.\n",
      "01 - Rico em vitamina\n",
      "02 - C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\n",
      "\n",
      "\n",
      "03 - Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado.\n",
      "04 - Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\n",
      "\n",
      "\n",
      "05 - Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano.\n",
      "06 - Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(suco_sentences_spacy):\n",
    "    print(f'{i:02d} - {sentence}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46d006-9f6b-4efb-b45e-8b76367596fd",
   "metadata": {},
   "source": [
    "#### Wrapping up in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2d463e6-7a72-469c-b6f7-b5a90721b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://spacy.io/models/en\n",
    "# https://spacy.io/models/pt\n",
    "\n",
    "# language = 'english', 'portuguese'\n",
    "# size = 'small', 'medium', 'large'\n",
    "def spacy_language_core(language='english', size='small') -> str:\n",
    "    languages_dict = {\n",
    "        'english': 'en_core_web_',\n",
    "        'portuguese': 'pt_core_news_'\n",
    "    }\n",
    "    \n",
    "    suffix_dict = {\n",
    "        'small': 'sm',\n",
    "        'medium': 'md',\n",
    "        'large': 'lg'\n",
    "    }\n",
    "    \n",
    "    if not language in languages_dict:\n",
    "        raise Exception(f'Invalid language: {language}. Available: {languages_dict.keys()}')\n",
    "        \n",
    "    if not size in suffix_dict:\n",
    "        raise Exception(f'Invalid size: {size}. Available: {suffix_dict.keys()}')\n",
    "    \n",
    "    core = languages_dict[language] + suffix_dict[size]\n",
    "    \n",
    "    return core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3084524-9045-4295-8efd-ae149ed92f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_core_web_sm\n"
     ]
    }
   ],
   "source": [
    "print(spacy_language_core())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7cd932f2-1406-4972-a51a-6f7b43aab392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def my_sent_tokenize_full(text: str, language='english') -> list:\n",
    "    core = spacy_language_core(language=language)\n",
    "    nlp = spacy.load(core)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42cf4761-62a0-44af-bd5b-a1a34e0b617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.',\n",
       " 'It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\\n\\n',\n",
       " 'One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.',\n",
       " 'This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\\n\\n',\n",
       " 'However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.',\n",
       " 'Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.',\n",
       " 'As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokenize_full(dl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "43d09bb6-36bf-494c-a5cd-a411fb02c0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante.',\n",
       " 'Rico em vitamina',\n",
       " 'C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\\n\\n',\n",
       " 'Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado.',\n",
       " 'Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\\n\\n',\n",
       " 'Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano.',\n",
       " 'Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent_tokenize_full(suco_text, language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fed70816-5bd0-49b3-996d-e3f79857540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version with the text already preprocessed by spaCy\n",
    "def my_sent_tokenize(doc: spacy.tokens.doc.Doc) -> list:\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4d51220-f69a-4f17-a52e-c6a67f2213d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.',\n",
       " 'It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\\n\\n',\n",
       " 'One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.',\n",
       " 'This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\\n\\n',\n",
       " 'However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.',\n",
       " 'Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.',\n",
       " 'As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(dl_text)\n",
    "\n",
    "my_sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f784702d-3510-4b01-8f38-58b022771b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suco de laranja √© uma bebida popular em todo o mundo devido ao seu sabor doce e refrescante.',\n",
       " 'Rico em vitamina',\n",
       " 'C e outros nutrientes, o suco de laranja √© conhecido por seus muitos benef√≠cios √† sa√∫de, incluindo o fortalecimento do sistema imunol√≥gico, a preven√ß√£o de doen√ßas card√≠acas e a melhoria da digest√£o.\\n\\n',\n",
       " 'Muitas pessoas preferem o sabor do suco de laranja fresco, espremido na hora, pois √© mais natural e cont√©m mais nutrientes do que o suco de laranja concentrado.',\n",
       " 'Algumas pessoas tamb√©m gostam de adicionar outras frutas ou ingredientes ao suco de laranja para dar um sabor extra, como lim√£o, abacaxi ou hortel√£.\\n\\n',\n",
       " 'Independentemente de como √© preparado, o suco de laranja √© uma bebida refrescante e nutritiva que pode ser apreciada em qualquer √©poca do ano.',\n",
       " 'Seja no caf√© da manh√£, no almo√ßo ou em qualquer outro momento, um copo de suco de laranja pode ser uma √≥tima maneira de obter uma dose de vitaminas e se refrescar ao mesmo tempo.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "doc = nlp(suco_text)\n",
    "\n",
    "my_sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abc9585-8e59-45c0-a688-55e294a86504",
   "metadata": {},
   "source": [
    "### 3.2. Lowercasing\n",
    "To prevent the _same word_ written with _different CASES_ from being interpreted _differently_ in future steps of NLP, we perform **lowering** to _standardize_ them with _lowercase letters_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20cb3063-3310-43f4-a35e-8aefde312502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My favorite ice cream flavor is Chocolate. Ow, I love CHOCOLATE ICE CreAM.'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_cream_text = 'My favorite ice cream flavor is Chocolate. Ow, I love CHOCOLATE ICE CreAM.'\n",
    "ice_cream_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3dffae05-f4c7-4f9c-ac1f-24bcd866e2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my favorite ice cream flavor is chocolate. ow, i love chocolate ice cream.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ice_cream_text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3ce7ff-470d-4743-be28-5c47acf14f65",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.3. Word tokenization\n",
    "#### NLTK\n",
    "- To **tokenize** a _sentence_ into **words**, we can start with a simple rule to split text into words based on the presence of **punctuation marks**.\n",
    "- The NLTK library allows us to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1e8735ec-3682-448a-a40e-ba1267d29e46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.',\n",
       " 'It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.',\n",
       " 'One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.',\n",
       " 'This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.',\n",
       " 'However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.',\n",
       " 'Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.',\n",
       " 'As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc1c856c-62b1-4c4e-a3e5-178b84ad35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ee39e87-8f41-4672-84aa-61f810b8621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works.\n",
      "['Deep', 'learning', 'is', 'a', 'subfield', 'of', 'machine', 'learning', 'that', 'uses', 'artificial', 'neural', 'networks', 'to', 'simulate', 'the', 'way', 'the', 'human', 'brain', 'works', '.']\n",
      "\n",
      "1 It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\n",
      "['It', 'involves', 'training', 'these', 'neural', 'networks', 'on', 'large', 'datasets', 'in', 'order', 'to', 'identify', 'complex', 'patterns', 'and', 'relationships', ',', 'which', 'can', 'then', 'be', 'used', 'to', 'make', 'predictions', 'or', 'perform', 'other', 'tasks', '.']\n",
      "\n",
      "2 One of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text.\n",
      "['One', 'of', 'the', 'key', 'advantages', 'of', 'deep', 'learning', 'is', 'its', 'ability', 'to', 'learn', 'from', 'unstructured', 'data', ',', 'such', 'as', 'images', ',', 'audio', ',', 'and', 'text', '.']\n",
      "\n",
      "3 This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\n",
      "['This', 'has', 'made', 'it', 'a', 'powerful', 'tool', 'for', 'a', 'wide', 'range', 'of', 'applications', ',', 'from', 'image', 'and', 'speech', 'recognition', 'to', 'natural', 'language', 'processing', 'and', 'autonomous', 'vehicles', '.']\n",
      "\n",
      "4 However, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively.\n",
      "['However', ',', 'deep', 'learning', 'can', 'also', 'be', 'computationally', 'intensive', 'and', 'requires', 'large', 'amounts', 'of', 'data', 'to', 'train', 'the', 'models', 'effectively', '.']\n",
      "\n",
      "5 Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing.\n",
      "['Nonetheless', ',', 'the', 'potential', 'benefits', 'of', 'deep', 'learning', 'are', 'enormous', ',', 'and', 'it', 'is', 'rapidly', 'becoming', 'an', 'essential', 'tool', 'in', 'fields', 'such', 'as', 'healthcare', ',', 'finance', ',', 'and', 'manufacturing', '.']\n",
      "\n",
      "6 As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.\n",
      "['As', 'researchers', 'continue', 'to', 'improve', 'the', 'algorithms', 'and', 'techniques', 'used', 'in', 'deep', 'learning', ',', 'we', 'can', 'expect', 'to', 'see', 'even', 'more', 'exciting', 'advances', 'in', 'the', 'years', 'to', 'come', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, sentence in enumerate(dl_sentences):\n",
    "    print(i, sentence)\n",
    "    print(word_tokenize(sentence))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59553f7f-406b-4b90-bc5d-a5bd1e09eb43",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We can also perform **word tokenization** in the _entire text_ directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4912c51f-3ae1-4715-9337-ad310be52a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'a',\n",
       " 'subfield',\n",
       " 'of',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'artificial',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'to',\n",
       " 'simulate',\n",
       " 'the',\n",
       " 'way',\n",
       " 'the',\n",
       " 'human',\n",
       " 'brain',\n",
       " 'works',\n",
       " '.',\n",
       " 'It',\n",
       " 'involves',\n",
       " 'training',\n",
       " 'these',\n",
       " 'neural',\n",
       " 'networks',\n",
       " 'on',\n",
       " 'large',\n",
       " 'datasets',\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'complex',\n",
       " 'patterns',\n",
       " 'and',\n",
       " 'relationships',\n",
       " ',',\n",
       " 'which',\n",
       " 'can',\n",
       " 'then',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'make',\n",
       " 'predictions',\n",
       " 'or',\n",
       " 'perform',\n",
       " 'other',\n",
       " 'tasks',\n",
       " '.',\n",
       " 'One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'key',\n",
       " 'advantages',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'is',\n",
       " 'its',\n",
       " 'ability',\n",
       " 'to',\n",
       " 'learn',\n",
       " 'from',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'images',\n",
       " ',',\n",
       " 'audio',\n",
       " ',',\n",
       " 'and',\n",
       " 'text',\n",
       " '.',\n",
       " 'This',\n",
       " 'has',\n",
       " 'made',\n",
       " 'it',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'tool',\n",
       " 'for',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'range',\n",
       " 'of',\n",
       " 'applications',\n",
       " ',',\n",
       " 'from',\n",
       " 'image',\n",
       " 'and',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'to',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " 'and',\n",
       " 'autonomous',\n",
       " 'vehicles',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'can',\n",
       " 'also',\n",
       " 'be',\n",
       " 'computationally',\n",
       " 'intensive',\n",
       " 'and',\n",
       " 'requires',\n",
       " 'large',\n",
       " 'amounts',\n",
       " 'of',\n",
       " 'data',\n",
       " 'to',\n",
       " 'train',\n",
       " 'the',\n",
       " 'models',\n",
       " 'effectively',\n",
       " '.',\n",
       " 'Nonetheless',\n",
       " ',',\n",
       " 'the',\n",
       " 'potential',\n",
       " 'benefits',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'are',\n",
       " 'enormous',\n",
       " ',',\n",
       " 'and',\n",
       " 'it',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'becoming',\n",
       " 'an',\n",
       " 'essential',\n",
       " 'tool',\n",
       " 'in',\n",
       " 'fields',\n",
       " 'such',\n",
       " 'as',\n",
       " 'healthcare',\n",
       " ',',\n",
       " 'finance',\n",
       " ',',\n",
       " 'and',\n",
       " 'manufacturing',\n",
       " '.',\n",
       " 'As',\n",
       " 'researchers',\n",
       " 'continue',\n",
       " 'to',\n",
       " 'improve',\n",
       " 'the',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'techniques',\n",
       " 'used',\n",
       " 'in',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'we',\n",
       " 'can',\n",
       " 'expect',\n",
       " 'to',\n",
       " 'see',\n",
       " 'even',\n",
       " 'more',\n",
       " 'exciting',\n",
       " 'advances',\n",
       " 'in',\n",
       " 'the',\n",
       " 'years',\n",
       " 'to',\n",
       " 'come',\n",
       " '.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(dl_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d274aec-a2e5-46af-a5c5-19770d10ad93",
   "metadata": {},
   "source": [
    "Note that the **punctuation was not *removed!***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e7d41-4afd-4237-8020-337cc53ca0ad",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25f0ea21-9bab-4e1b-93b6-18f18a68e77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subfield of machine learning that uses artificial neural networks to simulate the way the human brain works. It involves training these neural networks on large datasets in order to identify complex patterns and relationships, which can then be used to make predictions or perform other tasks.\\n\\nOne of the key advantages of deep learning is its ability to learn from unstructured data, such as images, audio, and text. This has made it a powerful tool for a wide range of applications, from image and speech recognition to natural language processing and autonomous vehicles.\\n\\nHowever, deep learning can also be computationally intensive and requires large amounts of data to train the models effectively. Nonetheless, the potential benefits of deep learning are enormous, and it is rapidly becoming an essential tool in fields such as healthcare, finance, and manufacturing. As researchers continue to improve the algorithms and techniques used in deep learning, we can expect to see even more exciting advances in the years to come.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1f3b82e7-f40b-45c0-a32a-5fadda9a1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b7284556-6c25-4b67-88d8-82dd563e46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(dl_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a61b33de-b442-4209-a998-238bf7a090e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b066fe11-bd56-4861-93ba-bc8d79d9114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep\n",
      "learning\n",
      "is\n",
      "a\n",
      "subfield\n",
      "of\n",
      "machine\n",
      "learning\n",
      "that\n",
      "uses\n",
      "artificial\n",
      "neural\n",
      "networks\n",
      "to\n",
      "simulate\n",
      "the\n",
      "way\n",
      "the\n",
      "human\n",
      "brain\n",
      "works\n",
      ".\n",
      "It\n",
      "involves\n",
      "training\n",
      "these\n",
      "neural\n",
      "networks\n",
      "on\n",
      "large\n",
      "datasets\n",
      "in\n",
      "order\n",
      "to\n",
      "identify\n",
      "complex\n",
      "patterns\n",
      "and\n",
      "relationships\n",
      ",\n",
      "which\n",
      "can\n",
      "then\n",
      "be\n",
      "used\n",
      "to\n",
      "make\n",
      "predictions\n",
      "or\n",
      "perform\n",
      "other\n",
      "tasks\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "One\n",
      "of\n",
      "the\n",
      "key\n",
      "advantages\n",
      "of\n",
      "deep\n",
      "learning\n",
      "is\n",
      "its\n",
      "ability\n",
      "to\n",
      "learn\n",
      "from\n",
      "unstructured\n",
      "data\n",
      ",\n",
      "such\n",
      "as\n",
      "images\n",
      ",\n",
      "audio\n",
      ",\n",
      "and\n",
      "text\n",
      ".\n",
      "This\n",
      "has\n",
      "made\n",
      "it\n",
      "a\n",
      "powerful\n",
      "tool\n",
      "for\n",
      "a\n",
      "wide\n",
      "range\n",
      "of\n",
      "applications\n",
      ",\n",
      "from\n",
      "image\n",
      "and\n",
      "speech\n",
      "recognition\n",
      "to\n",
      "natural\n",
      "language\n",
      "processing\n",
      "and\n",
      "autonomous\n",
      "vehicles\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "However\n",
      ",\n",
      "deep\n",
      "learning\n",
      "can\n",
      "also\n",
      "be\n",
      "computationally\n",
      "intensive\n",
      "and\n",
      "requires\n",
      "large\n",
      "amounts\n",
      "of\n",
      "data\n",
      "to\n",
      "train\n",
      "the\n",
      "models\n",
      "effectively\n",
      ".\n",
      "Nonetheless\n",
      ",\n",
      "the\n",
      "potential\n",
      "benefits\n",
      "of\n",
      "deep\n",
      "learning\n",
      "are\n",
      "enormous\n",
      ",\n",
      "and\n",
      "it\n",
      "is\n",
      "rapidly\n",
      "becoming\n",
      "an\n",
      "essential\n",
      "tool\n",
      "in\n",
      "fields\n",
      "such\n",
      "as\n",
      "healthcare\n",
      ",\n",
      "finance\n",
      ",\n",
      "and\n",
      "manufacturing\n",
      ".\n",
      "As\n",
      "researchers\n",
      "continue\n",
      "to\n",
      "improve\n",
      "the\n",
      "algorithms\n",
      "and\n",
      "techniques\n",
      "used\n",
      "in\n",
      "deep\n",
      "learning\n",
      ",\n",
      "we\n",
      "can\n",
      "expect\n",
      "to\n",
      "see\n",
      "even\n",
      "more\n",
      "exciting\n",
      "advances\n",
      "in\n",
      "the\n",
      "years\n",
      "to\n",
      "come\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126862d4-da16-447b-ba91-a5666b26c1ac",
   "metadata": {},
   "source": [
    "#### Word Tokenizers may be imprecise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ea021-effd-4956-b205-1211b4a8fcb8",
   "metadata": {},
   "source": [
    "**Example 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "394349ca-08ca-4a60-a6af-ecf6ef823895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Jack O‚ÄôNeil works at Melitas Marg, located at 245 Yonge Avenue, Austin, 70272.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_1 = \"Mr. Jack O‚ÄôNeil works at Melitas Marg, located at 245 Yonge Avenue, Austin, 70272.\"\n",
    "sentence_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64216cde-a7f4-48d0-b0fd-6722c16f695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mr.', 'Jack', 'O', '‚Äô', 'Neil', 'works', 'at', 'Melitas', 'Marg', ',', 'located', 'at', '245', 'Yonge', 'Avenue', ',', 'Austin', ',', '70272', '.']\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "print(word_tokenize(sentence_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce752847-da13-4c3d-8ee4-afeaaad1d8e3",
   "metadata": {},
   "source": [
    "Note that, using `NLTK`, _O, ‚Äò_, and _Neil_ are identified as three separate tokens, which is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc0d6331-b589-4895-b58c-3a146df68138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mr., Jack, O‚ÄôNeil, works, at, Melitas, Marg, ,, located, at, 245, Yonge, Avenue, ,, Austin, ,, 70272, .]\n"
     ]
    }
   ],
   "source": [
    "# spaCy\n",
    "doc = nlp(sentence_1)\n",
    "\n",
    "tokens = [token for token in doc]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929db945-330f-468a-915c-c1ec2c303898",
   "metadata": {},
   "source": [
    "Now, using `SpaCy`, O'Neil was considered a single token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a2d3e-c65c-4a2c-ab5a-3d3168d7ef37",
   "metadata": {},
   "source": [
    "**Example 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "060bad34-be6d-452b-bf01-1ba0f7147b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are $10,000 and ‚Ç¨1000 which are there just for testing a tokenizer'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_2 = \"There are $10,000 and ‚Ç¨1000 which are there just for testing a tokenizer\"\n",
    "sentence_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d936f069-233a-4bdb-89e5-c7225bb7441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', '$', '10,000', 'and', '‚Ç¨1000', 'which', 'are', 'there', 'just', 'for', 'testing', 'a', 'tokenizer']\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "print(word_tokenize(sentence_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da92669-040c-4423-9ff7-d6b6e4c9ac2a",
   "metadata": {},
   "source": [
    "While `$` and `10,000` are identified as _separate tokens_, `‚Ç¨1000` is identified as a _single token_ in `NLTK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5a509ea8-1535-42a6-8f9c-91c6bee3fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[There, are, $, 10,000, and, ‚Ç¨, 1000, which, are, there, just, for, testing, a, tokenizer]\n"
     ]
    }
   ],
   "source": [
    "# spaCy\n",
    "doc = nlp(sentence_2)\n",
    "\n",
    "tokens = [token for token in doc]\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75d12e-9881-43b0-a945-a1a61efd3e6d",
   "metadata": {},
   "source": [
    "Both money signs were identified as _separated tokens_ in `spaCy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f083b43-1bf7-4c5d-a5e3-7fe0faa0e29e",
   "metadata": {},
   "source": [
    "##### **Casual Word Tokenizers**\n",
    "In some cases, as Tweets or post in other social networks, the _standard word tokenization_ may be _even more imprecise_ due to **casual language** and **custom symbols** (e.g., @, #, ...). <br/>\n",
    "Some NLP packages, such as NLP, also provides a specific _word tokenizer_ for such cases.\n",
    "\n",
    "For example, NLTK `TweetTokenizer`: https://www.nltk.org/api/nltk.tokenize.casual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afa586-0163-4d67-86bb-dd80e01d5c93",
   "metadata": {},
   "source": [
    "##### **Tokenization is language-dependent**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e12449-805c-4159-a8b4-004cadc01a5b",
   "metadata": {},
   "source": [
    "**Tokenization** is also **_heavily_ dependent on language**.\n",
    "\n",
    "For example, **'N.Y.!'** has a total of _three punctuations_, but in English, **N.Y.** stands for New York, hence **'N.Y.'** should be treated as a **single word** and not be tokenized further.\n",
    "\n",
    "Such _language-specific exceptions_ can be specified in some NLP packages. NLTK treats this specific situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4919b5-fd54-47d8-9e82-1ee3c4b51bcb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.4. Correcting mis-spelled words\n",
    "- Be careful, because this preprocessing task might change the true meaning of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8459df-43e6-4b07-ad03-937c9f7f3377",
   "metadata": {},
   "source": [
    "**Required package - Text Blob**\n",
    "https://textblob.readthedocs.io/en/dev/\n",
    "\n",
    "`textblob` **only corrects spelling in English**. There is some alternative packages, such as [`pyspellchecker`](https://pyspellchecker.readthedocs.io/en/latest/), that supports Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c53c8958-c78a-45e0-bff9-af65cd841e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /home/hisamuka/yeah/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in /home/hisamuka/yeah/lib/python3.8/site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: joblib in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk>=3.1->textblob) (1.0.1)\n",
      "Requirement already satisfied: click in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk>=3.1->textblob) (8.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in /home/hisamuka/yeah/lib/python3.8/site-packages (from nltk>=3.1->textblob) (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28720a-c4a8-4cca-aa42-e1614ed64b62",
   "metadata": {},
   "source": [
    "#### **Correct spelling of a *word***\n",
    "It corrects _simple spelling mistakes_ as a repeated character and fat finger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "633fbbab-76cc-4605-89e7-4cf744eb63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "24837b03-8be5-4d87-9884-6022b1250997",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_be_corrected = 'appple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03ce434e-6517-429f-9e63-25a002aee0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apple'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(word_to_be_corrected).correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82ff65-2c29-4bbd-b02e-13c3448e1b47",
   "metadata": {},
   "source": [
    "#### **Correct spelling of a _sentence_***\n",
    "**`TextBlob()`** is a simple text block representation from the `textblob` library which has many useful methods, especially for **correcting the spelling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49404fa5-ce40-4586-8b9b-a82a315f2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "96bdaffb-2126-4de6-9ee9-968b7c16a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_be_corrected = 'A sentencee to checkk!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3dc90472-19fc-425c-aa01-14b2cbdffa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = TextBlob(sentence_to_be_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71a58805-9d7c-405b-961d-231ac46d77ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9cafafd-c18a-4ed0-adfa-437f265885fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"A sentence to check!\")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spelling correction\n",
    "corrected_sentence = sentence.correct()\n",
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ccfbc49-4935-4474-a7f9-4d180e2f7503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.TextBlob"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "53e28312-1134-4782-bce4-178488685605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A sentence to check!'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to string\n",
    "corrected_sentence = str(sentence.correct())\n",
    "corrected_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b9ea86d2-ee8e-4a8e-ba73-13df699a74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapping function to perform spelling correction\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def spelling_correction(sentence):\n",
    "    sentence_text_blob = TextBlob(sentence)\n",
    "    corrected_sentence = str(sentence_text_blob.correct())\n",
    "    \n",
    "    print(corrected_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "275561e4-d74f-48ea-a223-04c82fa01ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My favorit team is Barcelonah, they got sum amazin playas who can do all sortz of trickz with the balll.'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My favorit team is Barcelonah, they got sum amazin playas who can do all sortz of trickz with the balll.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4439bd93-d6cf-472f-932f-0387cf055dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By favorite team is Barcelonah, they got sum amazing plays who can do all sort of trick with the ball.\n"
     ]
    }
   ],
   "source": [
    "spelling_correction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5f786-5467-4453-92ff-2e21b964ecab",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "Note that the **spelling corrector _is not perfect_** but it helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1dc7f-ef60-4a19-837a-bc18e65f7ea2",
   "metadata": {},
   "source": [
    "### 3.5. Expand Contractions\n",
    "- To remove **stop words** in the next step, it is crucial that we deal with ***contractions*** first.\n",
    "- _Contractions_ are shorthand forms for words like _do not_ (***don‚Äôt***), _would not_ (***wouldn‚Äôt***), _it is_ (***it's***)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ec46b86b-4d5a-4dfe-8289-ffa07bbb1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTRACTION_MAP = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a5f5ec4d-be77-4b7c-bbe3-7403c60bfe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def expand_contractions(text, contraction_map=CONTRACTION_MAP, lower=False):\n",
    "    text_expanded = str(text)  # copy\n",
    "    if lower:\n",
    "        text_expanded = text_expanded.lower()\n",
    "    \n",
    "    for contraction, normal in contraction_map.items():\n",
    "        text_expanded = re.sub(contraction, normal, text_expanded)\n",
    "    \n",
    "    return text_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc04df21-fce9-4de9-bc87-dbfd0b72f908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ain't, aren't, can't, cause, can't've\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"ain't, aren't, can't, cause, can't've\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "24e46b7e-2565-47b5-84b6-f2ab798439fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"is not, are not, cannot, cause, cannot've\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ebe49646-48a1-4e49-b449-804a443e7435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm gonna tell you a little story about a guy who loved to travel. He'd go to all sorts of places, from big cities to small towns, and he'd always find something interesting to see or do. Sometimes he'd go with friends, but most of the time he'd go alone. That didn't bother him though, because he liked the freedom of being able to go wherever he wanted without having to worry about anyone else's schedule. And let me tell you, he saw some amazing things. From the top of mountains to the depths of the ocean, he saw it all. And he wouldn't have traded those experiences for anything.\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I'm gonna tell you a little story about a guy who loved to travel. He'd go to all sorts of places, from big cities to small towns, and he'd always find something interesting to see or do. Sometimes he'd go with friends, but most of the time he'd go alone. That didn't bother him though, because he liked the freedom of being able to go wherever he wanted without having to worry about anyone else's schedule. And let me tell you, he saw some amazing things. From the top of mountains to the depths of the ocean, he saw it all. And he wouldn't have traded those experiences for anything.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bdf94980-fae1-4ecc-a3ac-6dd9e7fbc879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i am gonna tell you a little story about a guy who loved to travel. he would go to all sorts of places, from big cities to small towns, and he would always find something interesting to see or do. sometimes he would go with friends, but most of the time he would go alone. that did not bother him though, because he liked the freedom of being able to go wherever he wanted without having to worry about anyone else's schedule. and let me tell you, he saw some amazing things. from the top of mountains to the depths of the ocean, he saw it all. and he would not have traded those experiences for anything.\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_contractions(text, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e16f6f-a2ac-4762-be75-81426bb4a72f",
   "metadata": {},
   "source": [
    "### 3.6. Remove _Stop Words_\n",
    "- Some of the **frequently used words** __are not particularly **useful**_ for some NLP tasks, for example, _tokenization_, _text classification_, _text summarization_, or any similar task.\n",
    "- In English, some examples of those words are: \"such as a, an, the, of, in, ...\"\n",
    "- These words, called **stop words**, don't don‚Äôt carry any content on their own.\n",
    "- **Stop words** are typically (though not always) _removed_ from further analysis in some NLP problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036cf3d-bcbe-406f-ab8e-49f38c154f9f",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "918578a4-fbfd-454a-875c-c2005eb6fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hisamuka/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "876c8bfc-8916-4875-98b0-1b02938a55ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arabic       chinese  french    hungarian   norwegian   slovene\n",
      "azerbaijani  danish   german    indonesian  portuguese  spanish\n",
      "basque       dutch    greek     italian     README      swedish\n",
      "bengali      english  hebrew    kazakh      romanian    tajik\n",
      "catalan      finnish  hinglish  nepali      russian     turkish\n"
     ]
    }
   ],
   "source": [
    "ls /home/hisamuka/nltk_data/corpora/stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0df0cfec-4f00-4aeb-acd4-6913a1ece9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def remove_stopwords_nltk(text, language='english'):\n",
    "    mystopwords = set(stopwords.words(language))\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tokens_without_stopwords = [token for token in tokens if not token.lower() in mystopwords]\n",
    "    text_without_stopwords = ' '.join(tokens_without_stopwords)\n",
    "    \n",
    "    return text_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e8fa6b6-1dd8-47bb-ab6c-aa32b69098e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample sentence, showing off the stop words filtration.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7201dada-212e-4dc2-98c4-510696d611bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample sentence , showing stop words filtration .'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords_nltk(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89aa72-c406-4847-bf37-ec7a248e6250",
   "metadata": {},
   "source": [
    "##### **Portuguese**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ce0357c5-7955-4370-8122-fe4d800b9e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Este √© um texto incr√≠vel, o melhor texto que voc√™ ler√° hoje, te garanto.'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Este √© um texto incr√≠vel, o melhor texto que voc√™ ler√° hoje, te garanto.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8abde2f-848e-464a-875b-c4931849235f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'texto incr√≠vel , melhor texto ler√° hoje , garanto .'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords_nltk(text, language='portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ac48fb-fc0d-4783-ac9a-5de23cdc345e",
   "metadata": {},
   "source": [
    "#### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "79f38e95-3fca-46a7-8dfd-4053efb4bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a sample sentence, showing off the stop words filtration.'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dfd3dc3d-2dbc-432b-9b02-0ed2e3571aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "181c0fbe-4830-411f-9c83-8dac845a630e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['using',\n",
       " 'other',\n",
       " '‚Äòd',\n",
       " 'two',\n",
       " 'take',\n",
       " 'anyway',\n",
       " 'around',\n",
       " 'throughout',\n",
       " 'there',\n",
       " 'become']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(stop_words)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5b9a5d54-e841-4447-949a-05f83ca618d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def remove_stopwords_full(text: str, language='english') -> list:\n",
    "    core = spacy_language_core(language)\n",
    "    nlp = spacy.load(core)\n",
    "        \n",
    "    doc = nlp(text)\n",
    "    tokens_without_stopwords = [token.text for token in doc if not token.is_stop]\n",
    "    text_without_stopwords = ' '.join(tokens_without_stopwords)\n",
    "            \n",
    "    return text_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d36b58bc-9f02-4665-92e6-e7f5b77f63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(doc: spacy.tokens.doc.Doc) -> list:\n",
    "    tokens_without_stopwords = [token.text for token in doc if not token.is_stop]\n",
    "    text_without_stopwords = ' '.join(tokens_without_stopwords)\n",
    "    return text_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19a9086f-ebb3-4b4f-aaca-d451f5b319d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample sentence , showing stop words filtration .'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords_full(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9cce5c04-3200-40ff-8e13-49a15025ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample sentence , showing stop words filtration .'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "remove_stopwords(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cb890-7682-4b5b-9c94-bb138783cfe5",
   "metadata": {},
   "source": [
    "### 3.7. Stemming and Lemmatization\n",
    "\n",
    "<img src='./imgs/stemming_vs_lemmatization.png' /> <br/>\n",
    "Source: https://www.kaggle.com/getting-started/186152\n",
    "\n",
    "<img src='./imgs/stemming_vs_lemmatization_2.png' /> <br/>\n",
    "Source: https://www.quora.com/What-is-difference-between-stemming-and-lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25fca4-3669-40e6-aaad-a056e7170a80",
   "metadata": {},
   "source": [
    "#### **Stemming**\n",
    "- Refers to the process of **removing suffixes and reducing a word to some *base (stem)*** form such that all different variants of that word can be represented by the _same form_..\n",
    "- The words obtained (_stems_) are not guaranteed to exist, which can be a problem depending on what we are solving.\n",
    "- **Porter Stemmer** and **Snowball Stemmer** are popular _stemming algorithms_ included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f009eeb1-4ac1-4bea-bd64-eb0e06c2bdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['develop', 'developed', 'developing', 'development']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "666dd077-5ae7-4d25-885d-df1e750ac195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PorterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "51f631f9-9277-479a-aa2d-d668703746e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Stem\n",
      "---------------|---------------\n",
      "develop        | develop       \n",
      "developed      | develop       \n",
      "developing     | develop       \n",
      "development    | develop       \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "899219b3-8133-4f4f-acd5-dca283bed126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c9925a51-d15b-4ec4-a117-5e55eefe9227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Stem\n",
      "---------------|---------------\n",
      "develop        | develop       \n",
      "developed      | develop       \n",
      "developing     | develop       \n",
      "development    | develop       \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = snow_stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861488b-ba8b-4793-ba61-d1304c6d171d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### **Portuguese**\n",
    "- **RSLPStemmer** is a popular _stemming algorithm_ designed for **Portuguese**, which is also included in NLTK.\n",
    "- We can also use **Snowball Stemmer** for _Portuguese_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "66d66977-65d5-4267-81d9-90c689f6478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['amigo', 'amizade', 'amigas', 'amig√£o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c8bf8a0b-f9b8-4eb8-b706-6cf6f5955630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/hisamuka/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RSLPStemmer\n",
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a926485d-d3a0-49ea-83ba-129c941e179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import RSLPStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1bd5e1eb-608e-4e0b-b294-9af557a26e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eb514aad-8431-42d0-8f68-95a4828f8277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Stem\n",
      "---------------|---------------\n",
      "amigo          | amig          \n",
      "amizade        | amizad        \n",
      "amigas         | amig          \n",
      "amig√£o         | amig          \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ec27be0-7eff-4fb0-9113-aba4898cad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowballStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "snow_stemmer = SnowballStemmer(language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d68a4816-6101-41d2-8f68-5f9a8c7d6710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Stem\n",
      "---------------|---------------\n",
      "amigo          | amig          \n",
      "amizade        | amizad        \n",
      "amigas         | amig          \n",
      "amig√£o         | amig√£         \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Stem')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    stem = snow_stemmer.stem(word)\n",
    "    print(f'{word:14} | {stem:14}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefcd790-ab9d-4c8d-a2b1-a1677bce76ac",
   "metadata": {},
   "source": [
    "#### **Lemmatization**\n",
    "- The process of ***mapping* all the different forms of a word to its *base word (lemma)***.\n",
    "- Requires more _linguistic knowledge_ than _stemming_.\n",
    "- **WordNet** is a popular lemmatization algorithm_ included in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "806cd18b-1c08-41fd-a18c-4b2f0c48fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['drive', 'drives', 'drove', 'driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b28df257-b3fb-4a50-8c5a-78ed046359b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hisamuka/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the lemmas\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a4302f06-2c76-4cfd-8724-1e768c6b71a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "695ae5ec-b575-464e-9d07-749e2ea54aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Lemma\n",
      "---------------|---------------\n",
      "drive          | drive         \n",
      "drives         | drive         \n",
      "drove          | drive         \n",
      "driven         | drive         \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    # pos='v' means the word to be analyzed is a verb\n",
    "    # we need to be explicit here\n",
    "    # there are other options: e.g., 'a' for adjectives\n",
    "    lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "    print(f'{word:14} | {lemma:14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4ebee451-5ed5-4c8f-a7fb-20696c4eee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n"
     ]
    }
   ],
   "source": [
    "# lemmatization for an adjective\n",
    "print(lemmatizer.lemmatize('better', pos='a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964276b-383d-48e1-ad5e-1eecb85b126e",
   "metadata": {},
   "source": [
    "#### **Stemming and Lemmatization** in `spaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b079858d-b075-4328-aa84-4fd3476675eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7ab7cbab-bf4a-4a63-9c9c-b0f42f503569",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('better')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2d7e09d7-69ea-4b0f-8cfd-3e3184bf2323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "21b2f192-c724-4f94-b1d3-5815b4d8ac19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: better ==> Lemma: well\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'Word: {token.text} ==> Lemma: {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bd5d62df-8d99-4e88-acee-f7640a2693bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['drive', 'drives', 'drove', 'driven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9825665f-d0e1-47a2-a912-37afe889f610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Lemma\n",
      "---------------|---------------\n",
      "drive          | drive\n",
      "drives         | drive\n",
      "drove          | drive\n",
      "driven         | drive\n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        print(f'{token.text:14} | {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21376023-60fe-4453-a407-e7fa738d354b",
   "metadata": {},
   "source": [
    "##### **Portuguese**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "239b106a-1492-4252-9f80-845bda846f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "090efad3-0158-4dd2-885b-cc5ec5c2b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = ['amigo', 'amizade', 'amigas', 'amig√£o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a12324fe-0378-4506-bbfd-5e5ace495e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | Lemma\n",
      "---------------|---------------\n",
      "amigo          | amigar\n",
      "amizade        | amizade\n",
      "amigas         | amigo\n",
      "amig√£o         | amig√£o\n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | Lemma')\n",
    "print(f'---------------|---------------')\n",
    "\n",
    "for word in word_list:\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        print(f'{token.text:14} | {token.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d09dd52-3e53-4bc9-af62-15720ce32a2d",
   "metadata": {},
   "source": [
    "### 3.8. Part-Of-Speech (POS) Tagging\n",
    "- Also called ***grammatical tagging***, it is the _automatic assignment_ of **POS tags** to _words_ in a sentence.\n",
    "- A **POS** is a _grammatical_ classification that commonly includes verbs, adjectives, adverbs, nouns, etc.\n",
    "- **POS tags** make it possible for _automatic text processing tools_ to take into account which part of speech each word is.\n",
    "- This facilitates the use of linguistic criteria in addition to statistics.\n",
    "- For languages where the same word can have different parts of speech, e.g. work in English, **POS tags** are used to distinguish between the occurrences of the word when used as a noun or verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011fd5c2-26a5-45fd-bf29-9c0ae8c51ede",
   "metadata": {},
   "source": [
    "#### View token tags\n",
    "Recall that you can obtain a particular token by its index position.\n",
    "* To view the coarse POS tag use `token.pos_`\n",
    "* To view the fine-grained tag use `token.tag_`\n",
    "* To view the description of either type of tag use `spacy.explain(tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47cf1ae5-61d4-4a91-be6b-cbc18d0000ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bill = \"Bill Gates is an American entrepreneur and philanthropist who co-founded Microsoft Corporation in 1975.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4117cea6-0258-426a-9413-89f23b8e2544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ea4ca410-68fc-4a1e-83fc-e23d1141fd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Process the text with spaCy\n",
    "doc = nlp(text_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "69484071-8b8d-47ef-bc3b-347b21b867ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | POS tag  | Tag    | Explanation POS\n",
      "---------------|----------|--------|----------------\n",
      "Bill           | PROPN    | NNP    | proper noun   \n",
      "Gates          | PROPN    | NNP    | proper noun   \n",
      "is             | AUX      | VBZ    | auxiliary     \n",
      "an             | DET      | DT     | determiner    \n",
      "American       | ADJ      | JJ     | adjective     \n",
      "entrepreneur   | NOUN     | NN     | noun          \n",
      "and            | CCONJ    | CC     | coordinating conjunction\n",
      "philanthropist | NOUN     | NN     | noun          \n",
      "who            | PRON     | WP     | pronoun       \n",
      "co             | VERB     | VBD    | verb          \n",
      "-              | VERB     | VBD    | verb          \n",
      "founded        | VERB     | VBD    | verb          \n",
      "Microsoft      | PROPN    | NNP    | proper noun   \n",
      "Corporation    | PROPN    | NNP    | proper noun   \n",
      "in             | ADP      | IN     | adposition    \n",
      "1975           | NUM      | CD     | numeral       \n",
      ".              | PUNCT    | .      | punctuation   \n"
     ]
    }
   ],
   "source": [
    "print(f'Word           | POS tag  | Tag    | Explanation POS')\n",
    "print(f'---------------|----------|--------|----------------')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:14} | {token.pos_:{8}} | {token.tag_:{6}} | {spacy.explain(token.pos_):{14}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637ff69-380a-4e5e-9864-fee7aa6cfe5e",
   "metadata": {},
   "source": [
    "#### Coarse-grained Part-of-speech Tags\n",
    "Every token is assigned a POS Tag from the following list:\n",
    "\n",
    "\n",
    "<table><tr><th>POS</th><th>DESCRIPTION</th><th>EXAMPLES</th></tr>\n",
    "    \n",
    "<tr><td>ADJ</td><td>adjective</td><td>*big, old, green, incomprehensible, first*</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>*in, to, during*</td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>*very, tomorrow, down, where, there*</td></tr>\n",
    "<tr><td>AUX</td><td>auxiliary</td><td>*is, has (done), will (do), should (do)*</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>CCONJ</td><td>coordinating conjunction</td><td>*and, or, but*</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>*a, an, the*</td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>*psst, ouch, bravo, hello*</td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>*girl, cat, tree, air, beauty*</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>*1, 2017, one, seventy-seven, IV, MMXIV*</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>*'s, not,*</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>*I, you, he, she, myself, themselves, somebody*</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>*Mary, John, London, NATO, HBO*</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>*., (, ), ?*</td></tr>\n",
    "<tr><td>SCONJ</td><td>subordinating conjunction</td><td>*if, while, that*</td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>*$, %, ¬ß, ¬©, +, ‚àí, √ó, √∑, =, :), üòù*</td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>*run, runs, running, eat, ate, eating*</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>*sfpksdpsxmsa*</td></tr>\n",
    "<tr><td>SPACE</td><td>space</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600eae0-fb9c-4881-aa16-30132a5dc9c0",
   "metadata": {},
   "source": [
    "___\n",
    "## Fine-grained Part-of-speech Tags\n",
    "Tokens are subsequently given a fine-grained tag as determined by morphology:\n",
    "<table>\n",
    "<tr><th>POS</th><th>Description</th><th>Fine-grained Tag</th><th>Description</th><th>Morphology</th></tr>\n",
    "<tr><td>ADJ</td><td>adjective</td><td>AFX</td><td>affix</td><td>Hyph=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJ</td><td>adjective</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJR</td><td>adjective, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>JJS</td><td>adjective, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PDT</td><td>predeterminer</td><td>AdjType=pdt PronType=prn</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>PRP\\$</td><td>pronoun, possessive</td><td>PronType=prs Poss=yes</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WDT</td><td>wh-determiner</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>ADJ</td><td></td><td>WP\\$</td><td>wh-pronoun, possessive</td><td>Poss=yes PronType=int rel</td></tr>\n",
    "<tr><td>ADP</td><td>adposition</td><td>IN</td><td>conjunction, subordinating or preposition</td><td></td></tr>\n",
    "<tr><td>ADV</td><td>adverb</td><td>EX</td><td>existential there</td><td>AdvType=ex</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RB</td><td>adverb</td><td>Degree=pos</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBR</td><td>adverb, comparative</td><td>Degree=comp</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>RBS</td><td>adverb, superlative</td><td>Degree=sup</td></tr>\n",
    "<tr><td>ADV</td><td></td><td>WRB</td><td>wh-adverb</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>CONJ</td><td>conjunction</td><td>CC</td><td>conjunction, coordinating</td><td>ConjType=coor</td></tr>\n",
    "<tr><td>DET</td><td>determiner</td><td>DT</td><td>determiner</td><td></td></tr>\n",
    "<tr><td>INTJ</td><td>interjection</td><td>UH</td><td>interjection</td><td></td></tr>\n",
    "<tr><td>NOUN</td><td>noun</td><td>NN</td><td>noun, singular or mass</td><td>Number=sing</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>NNS</td><td>noun, plural</td><td>Number=plur</td></tr>\n",
    "<tr><td>NOUN</td><td></td><td>WP</td><td>wh-pronoun, personal</td><td>PronType=int rel</td></tr>\n",
    "<tr><td>NUM</td><td>numeral</td><td>CD</td><td>cardinal number</td><td>NumType=card</td></tr>\n",
    "<tr><td>PART</td><td>particle</td><td>POS</td><td>possessive ending</td><td>Poss=yes</td></tr>\n",
    "<tr><td>PART</td><td></td><td>RP</td><td>adverb, particle</td><td></td></tr>\n",
    "<tr><td>PART</td><td></td><td>TO</td><td>infinitival to</td><td>PartType=inf VerbForm=inf</td></tr>\n",
    "<tr><td>PRON</td><td>pronoun</td><td>PRP</td><td>pronoun, personal</td><td>PronType=prs</td></tr>\n",
    "<tr><td>PROPN</td><td>proper noun</td><td>NNP</td><td>noun, proper singular</td><td>NounType=prop Number=sign</td></tr>\n",
    "<tr><td>PROPN</td><td></td><td>NNPS</td><td>noun, proper plural</td><td>NounType=prop Number=plur</td></tr>\n",
    "<tr><td>PUNCT</td><td>punctuation</td><td>-LRB-</td><td>left round bracket</td><td>PunctType=brck PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>-RRB-</td><td>right round bracket</td><td>PunctType=brck PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>,</td><td>punctuation mark, comma</td><td>PunctType=comm</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>:</td><td>punctuation mark, colon or ellipsis</td><td></td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>.</td><td>punctuation mark, sentence closer</td><td>PunctType=peri</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>''</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>\"\"</td><td>closing quotation mark</td><td>PunctType=quot PunctSide=fin</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>``</td><td>opening quotation mark</td><td>PunctType=quot PunctSide=ini</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>HYPH</td><td>punctuation mark, hyphen</td><td>PunctType=dash</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>LS</td><td>list item marker</td><td>NumType=ord</td></tr>\n",
    "<tr><td>PUNCT</td><td></td><td>NFP</td><td>superfluous punctuation</td><td></td></tr>\n",
    "<tr><td>SYM</td><td>symbol</td><td>#</td><td>symbol, number sign</td><td>SymType=numbersign</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>\\$</td><td>symbol, currency</td><td>SymType=currency</td></tr>\n",
    "<tr><td>SYM</td><td></td><td>SYM</td><td>symbol</td><td></td></tr>\n",
    "<tr><td>VERB</td><td>verb</td><td>BES</td><td>auxiliary \"be\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>HVS</td><td>forms of \"have\"</td><td></td></tr>\n",
    "<tr><td>VERB</td><td></td><td>MD</td><td>verb, modal auxiliary</td><td>VerbType=mod</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VB</td><td>verb, base form</td><td>VerbForm=inf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBD</td><td>verb, past tense</td><td>VerbForm=fin Tense=past</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBG</td><td>verb, gerund or present participle</td><td>VerbForm=part Tense=pres Aspect=prog</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBN</td><td>verb, past participle</td><td>VerbForm=part Tense=past Aspect=perf</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBP</td><td>verb, non-3rd person singular present</td><td>VerbForm=fin Tense=pres</td></tr>\n",
    "<tr><td>VERB</td><td></td><td>VBZ</td><td>verb, 3rd person singular present</td><td>VerbForm=fin Tense=pres Number=sing Person=3</td></tr>\n",
    "<tr><td>X</td><td>other</td><td>ADD</td><td>email</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>FW</td><td>foreign word</td><td>Foreign=yes</td></tr>\n",
    "<tr><td>X</td><td></td><td>GW</td><td>additional word in multi-word expression</td><td></td></tr>\n",
    "<tr><td>X</td><td></td><td>XX</td><td>unknown</td><td></td></tr>\n",
    "<tr><td>SPACE</td><td>space</td><td>_SP</td><td>space</td><td></td></tr>\n",
    "<tr><td></td><td></td><td>NIL</td><td>missing tag</td><td></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a442f6-13c7-4daa-a3d9-b4f8c378bddd",
   "metadata": {},
   "source": [
    "#### Visualizing Parts of Speech\n",
    "spaCy offers an outstanding visualizer called **displaCy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3e929ca8-ea94-4fad-94fe-7cbc5deb6782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the displaCy library\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3b9efd00-b729-47d7-863a-6ec1825d4873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2c19011de83640bb99780248a56fe23b-0\" class=\"displacy\" width=\"1700\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Bill</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">Gates</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">an</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">American</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">entrepreneur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">philanthropist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">who</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">co-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">founded</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">Microsoft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">Corporation</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">1975.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,112.0 260.0,112.0 260.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L172,157.0 188,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-2\" stroke-width=\"2px\" d=\"M400,167.0 C400,57.0 595.0,57.0 595.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-3\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510,169.0 L502,157.0 518,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-4\" stroke-width=\"2px\" d=\"M290,167.0 C290,2.0 600.0,2.0 600.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M600.0,169.0 L608.0,157.0 592.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-5\" stroke-width=\"2px\" d=\"M620,167.0 C620,112.0 700.0,112.0 700.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700.0,169.0 L708.0,157.0 692.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-6\" stroke-width=\"2px\" d=\"M620,167.0 C620,57.0 815.0,57.0 815.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,169.0 L823.0,157.0 807.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-7\" stroke-width=\"2px\" d=\"M950,167.0 C950,57.0 1145.0,57.0 1145.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950,169.0 L942,157.0 958,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-8\" stroke-width=\"2px\" d=\"M1060,167.0 C1060,112.0 1140.0,112.0 1140.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,169.0 L1052,157.0 1068,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-9\" stroke-width=\"2px\" d=\"M840,167.0 C840,2.0 1150.0,2.0 1150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,169.0 L1158.0,157.0 1142.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-10\" stroke-width=\"2px\" d=\"M1280,167.0 C1280,112.0 1360.0,112.0 1360.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1280,169.0 L1272,157.0 1288,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-11\" stroke-width=\"2px\" d=\"M1170,167.0 C1170,57.0 1365.0,57.0 1365.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,169.0 L1373.0,157.0 1357.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-12\" stroke-width=\"2px\" d=\"M1170,167.0 C1170,2.0 1480.0,2.0 1480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1480.0,169.0 L1488.0,157.0 1472.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c19011de83640bb99780248a56fe23b-0-13\" stroke-width=\"2px\" d=\"M1500,167.0 C1500,112.0 1580.0,112.0 1580.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c19011de83640bb99780248a56fe23b-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1580.0,169.0 L1588.0,157.0 1572.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86779fd4-862c-412c-aae3-95c67a0e3af1",
   "metadata": {},
   "source": [
    "#### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "138f4888-c88f-4faa-92b5-682dadf3aa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maur√≠cio de Sousa √© o criador da Turma da M√¥nica, uma s√©rie de gibis brasileiros que foi criada em 1959.'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_mau = 'Maur√≠cio de Sousa √© o criador da Turma da M√¥nica, uma s√©rie de gibis brasileiros que foi criada em 1959.'\n",
    "text_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "23869281-b876-4468-9559-d7649a0527d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word           | POS tag  | Explanation POS | Tag    \n",
      "---------------|----------|-----------------|----------------\n",
      "Maur√≠cio       | PROPN    | proper noun     | PROPN__Gender=Masc|Number=Sing\n",
      "de             | ADP      | adposition      | ADP   \n",
      "Sousa          | PROPN    | proper noun     | PROPN__Number=Sing\n",
      "√©              | AUX      | auxiliary       | AUX__Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "o              | DET      | determiner      | DET__Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "criador        | NOUN     | noun            | NOUN__Gender=Masc|Number=Sing\n",
      "da             | DET      | determiner      | ADP_DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "Turma          | PROPN    | proper noun     | PROPN__Gender=Fem|Number=Sing\n",
      "da             | DET      | determiner      | ADP_DET__Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "M√¥nica         | PROPN    | proper noun     | PROPN__Number=Sing\n",
      ",              | PUNCT    | punctuation     | PUNCT \n",
      "uma            | DET      | determiner      | DET__Definite=Ind|Gender=Fem|Number=Sing|PronType=Art\n",
      "s√©rie          | NOUN     | noun            | NOUN__Gender=Fem|Number=Sing\n",
      "de             | ADP      | adposition      | ADP   \n",
      "gibis          | NOUN     | noun            | NOUN__Gender=Fem|Number=Sing\n",
      "brasileiros    | ADJ      | adjective       | ADJ__Gender=Masc|Number=Plur\n",
      "que            | PRON     | pronoun         | PRON__Gender=Masc|Number=Sing|PronType=Rel\n",
      "foi            | AUX      | auxiliary       | AUX__Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\n",
      "criada         | VERB     | verb            | VERB__Gender=Fem|Number=Sing|VerbForm=Part|Voice=Pass\n",
      "em             | ADP      | adposition      | ADP   \n",
      "1959           | NUM      | numeral         | NUM__NumType=Card\n",
      ".              | PUNCT    | punctuation     | PUNCT \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary\n",
    "\n",
    "doc = nlp(text_mau)\n",
    "\n",
    "print(f'Word           | POS tag  | Explanation POS | Tag    ')\n",
    "print(f'---------------|----------|-----------------|----------------')\n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:14} | {token.pos_:{8}} | {spacy.explain(token.pos_):{15}} | {token.tag_:{6}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4caecb-879b-4034-acc8-b7df6fee063c",
   "metadata": {},
   "source": [
    "### 3.9. Named-Entity Recognition (NER)\n",
    "- **NER** tries to find out whether or not a word is a ***named entity***.\n",
    "- ***Named entities*** are persons, locations, organizations, time expressions etc.\n",
    "- This problem can be broken down into _detection of names_ followed by _classification of name_ into the corresponding categories.\n",
    "- Most often a word recognized by **NER** may be recognized as a ***noun*** by a _POS tagger_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5a5d02f0-8b81-4a19-9392-392d248fa6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bill Gates is an American entrepreneur and philanthropist who co-founded Microsoft Corporation in 1975.'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9f19f32e-f123-4dbc-a941-c8fd31264c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "70ce5973-4171-43fb-a12e-554799ae8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text_bill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b8e44d7f-031b-41c3-8149-8bbfeb46bec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                   | NER           | Explanation\n",
      "-----------------------|---------------|-------------------------------\n",
      "Bill Gates             | PERSON        | People, including fictional   \n",
      "American               | NORP          | Nationalities or religious or political groups\n",
      "Microsoft Corporation  | ORG           | Companies, agencies, institutions, etc.\n",
      "1975                   | DATE          | Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "print(f'Word                   | NER           | Explanation')\n",
    "print(f'-----------------------|---------------|-------------------------------')\n",
    "\n",
    "# Print the named entities in the text\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:22} | {ent.label_:13} | {spacy.explain(ent.label_):30}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07edfc1b-c1ae-4396-8167-4eaf1a0cd633",
   "metadata": {},
   "source": [
    "#### Entity annotations\n",
    "`Doc.ents` are token spans with their own set of annotations.\n",
    "<table>\n",
    "<tr><td>`ent.text`</td><td>The original entity text</td></tr>\n",
    "<tr><td>`ent.label`</td><td>The entity type's hash value</td></tr>\n",
    "<tr><td>`ent.label_`</td><td>The entity type's string description</td></tr>\n",
    "<tr><td>`ent.start`</td><td>The token span's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end`</td><td>The token span's *stop* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.start_char`</td><td>The entity text's *start* index position in the Doc</td></tr>\n",
    "<tr><td>`ent.end_char`</td><td>The entity text's *stop* index position in the Doc</td></tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab38681-38c6-4dd8-b1c8-d4b593edbc41",
   "metadata": {},
   "source": [
    "We can **extend the *NER*** library in `spaCy`:\n",
    "- https://towardsdatascience.com/extend-named-entity-recogniser-ner-to-label-new-entities-with-spacy-339ee5979044"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657612e-3b7e-401d-87b7-dc09061ef7b8",
   "metadata": {},
   "source": [
    "#### Visualizing NER\n",
    "- https://spacy.io/usage/visualizers#ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5f7d8512-a80a-4bb3-9b37-f8b3a6c4f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4654fb80-decb-4e5a-af52-f9b426cb3953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill Gates\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is an \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " entrepreneur and philanthropist who co-founded \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft Corporation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1975\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d287b91-37d6-4a37-b06e-1915694c0503",
   "metadata": {},
   "source": [
    "#### Portuguese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "76157beb-7ba6-46ec-a25a-c6477b4dde01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maur√≠cio de Sousa √© o criador da Turma da M√¥nica, uma s√©rie de gibis brasileiros que foi criada em 1959.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_mau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae07ea52-34f8-416a-9af7-5a82fe022c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_sm')  # small vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9bea5878-153d-4a2b-b53c-0d7e59ff4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text_mau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0a67d409-efb5-48cb-8764-c124b8a20ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                   | NER           | Explanation\n",
      "-----------------------|---------------|-------------------------------\n",
      "Maur√≠cio de Sousa      | PER           | Named person or family.       \n",
      "Turma da M√¥nica        | PER           | Named person or family.       \n"
     ]
    }
   ],
   "source": [
    "print(f'Word                   | NER           | Explanation')\n",
    "print(f'-----------------------|---------------|-------------------------------')\n",
    "\n",
    "# Print the named entities in the text\n",
    "for ent in doc.ents:\n",
    "    print(f'{ent.text:22} | {ent.label_:13} | {spacy.explain(ent.label_):30}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f3d06-9c8c-4073-87b2-9a2b2ef43ef3",
   "metadata": {},
   "source": [
    "The year **wasn't** identified as a **NER**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "323d95f8-2576-4d2b-a890-b6e4bf1bc7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Maur√≠cio de Sousa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " √© o criador da \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Turma da M√¥nica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", uma s√©rie de gibis brasileiros que foi criada em 1959.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e94daa-39b0-477c-8c8c-1be2048deea3",
   "metadata": {},
   "source": [
    "## See more:\n",
    "- https://www.alura.com.br/artigos/lemmatization-vs-stemming-quando-usar-cada-uma\n",
    "- https://www.askpython.com/python/examples/pos-tagging-in-nlp-using-spacy\n",
    "- https://towardsdatascience.com/text-preprocessing-in-natural-language-processing-using-python-6113ff5decd8\n",
    "- https://medium.com/product-ai/text-preprocessing-in-python-steps-tools-and-examples-bf025f872908\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
